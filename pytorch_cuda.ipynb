{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.10 64-bit ('dl': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "interpreter": {
      "hash": "043e9f5fba74f1b043c35e82e8aa7319d9828ad06fee4b2fbca4cca1ab6c980b"
    },
    "colab": {
      "name": "pytorch_cuda.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJZz72BtXLzP"
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "V93izisBXLzU",
        "outputId": "2688e34e-257d-4222-9dc9-d0e1f5259092"
      },
      "source": [
        "df = pd.read_csv(\"height-weight-25k.csv\")\n",
        "df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Height-Inches</th>\n",
              "      <th>Weight-Pounds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>65.78331</td>\n",
              "      <td>112.9925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>71.51521</td>\n",
              "      <td>136.4873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>69.39874</td>\n",
              "      <td>153.0269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>68.21660</td>\n",
              "      <td>142.3354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>67.78781</td>\n",
              "      <td>144.2971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Index  Height-Inches  Weight-Pounds\n",
              "0      1       65.78331       112.9925\n",
              "1      2       71.51521       136.4873\n",
              "2      3       69.39874       153.0269\n",
              "3      4       68.21660       142.3354\n",
              "4      5       67.78781       144.2971"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "JDQDgpZ6XLzW",
        "outputId": "508f3eb1-c47a-41f7-8729-eac5f0be7cf5"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Height-Inches</th>\n",
              "      <th>Weight-Pounds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>12500.500000</td>\n",
              "      <td>67.993114</td>\n",
              "      <td>127.079421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7217.022701</td>\n",
              "      <td>1.901679</td>\n",
              "      <td>11.660898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.278360</td>\n",
              "      <td>78.014760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6250.750000</td>\n",
              "      <td>66.704397</td>\n",
              "      <td>119.308675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>12500.500000</td>\n",
              "      <td>67.995700</td>\n",
              "      <td>127.157750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>18750.250000</td>\n",
              "      <td>69.272958</td>\n",
              "      <td>134.892850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>25000.000000</td>\n",
              "      <td>75.152800</td>\n",
              "      <td>170.924000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Index  Height-Inches  Weight-Pounds\n",
              "count  25000.000000   25000.000000   25000.000000\n",
              "mean   12500.500000      67.993114     127.079421\n",
              "std     7217.022701       1.901679      11.660898\n",
              "min        1.000000      60.278360      78.014760\n",
              "25%     6250.750000      66.704397     119.308675\n",
              "50%    12500.500000      67.995700     127.157750\n",
              "75%    18750.250000      69.272958     134.892850\n",
              "max    25000.000000      75.152800     170.924000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P_9kc-aXLzX"
      },
      "source": [
        "y = df['Weight-Pounds'].values # Target\n",
        "y = y.reshape(-1, 1)\n",
        "X = df['Height-Inches'].values # Feature \n",
        "X = X.reshape(-1, 1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRHVglLkXLzY",
        "outputId": "4e9a0ff7-f1a8-4ce7-fd71-fc9193adf2ac"
      },
      "source": [
        "# train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 1) (20000, 1)\n",
            "(5000, 1) (5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x79WKRjMXLzY",
        "outputId": "098bae76-fea4-413d-ce1c-1e4f8bca413c"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmvgP4ZMXLzZ"
      },
      "source": [
        "# train data\n",
        "x_train = np.array(X_train, dtype=np.float32)\n",
        "x_train = x_train.reshape(-1, 1)\n",
        "y_train = np.array(y_train, dtype=np.float32)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "# test data\n",
        "x_test = np.array(X_test, dtype=np.float32)\n",
        "x_test = x_test.reshape(-1, 1)\n",
        "y_test = np.array(y_test, dtype=np.float32)\n",
        "y_test = y_test.reshape(-1, 1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BjclovbXLza"
      },
      "source": [
        "# model\n",
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "    \n",
        "    def forward(self, x): \n",
        "        out = self.linear(x) \n",
        "        return out"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkrGK4IOXLzb",
        "outputId": "26338228-f271-427a-c54c-07737e4a4121"
      },
      "source": [
        "# model with CUDA\n",
        "inputDim = 1 # x \n",
        "outputDim = 1 # y \n",
        "learningRate = 0.0001\n",
        "epochs = 1000\n",
        "model = linearRegression(inputDim, outputDim)\n",
        "model.cuda()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "linearRegression(\n",
              "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGImxeDeXLzc"
      },
      "source": [
        "# SGD and loss function\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxOgRTVYXz_N",
        "outputId": "0d888cb6-aaaf-4224-d709-a7a2e8446e75"
      },
      "source": [
        "# training\n",
        "for epoch in range(epochs):\n",
        "  inputs = Variable(torch.from_numpy(x_train).cuda()) \n",
        "  labels = Variable(torch.from_numpy(y_train).cuda()) \n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, labels)\n",
        "  print(loss)\n",
        "  # get gradients\n",
        "  loss.backward()\n",
        "  # update parameters\n",
        "  optimizer.step()\n",
        "  print('epoch {}, loss {}'.format(epoch, loss.item()))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(25582.7363, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 0, loss 25582.736328125\n",
            "tensor(249.1567, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 1, loss 249.1566619873047\n",
            "tensor(108.1178, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 2, loss 108.11781311035156\n",
            "tensor(107.3326, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 3, loss 107.33259582519531\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 4, loss 107.3282241821289\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 5, loss 107.32819366455078\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 6, loss 107.32819366455078\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 7, loss 107.32819366455078\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 8, loss 107.32818603515625\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 9, loss 107.32819366455078\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 10, loss 107.32818603515625\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 11, loss 107.32818603515625\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 12, loss 107.32818603515625\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 13, loss 107.32818603515625\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 14, loss 107.32818603515625\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 15, loss 107.32818603515625\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 16, loss 107.32818603515625\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 17, loss 107.32817077636719\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 18, loss 107.32817077636719\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 19, loss 107.32817077636719\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 20, loss 107.32817077636719\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 21, loss 107.32817077636719\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 22, loss 107.32817077636719\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 23, loss 107.32816314697266\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 24, loss 107.32816314697266\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 25, loss 107.32816314697266\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 26, loss 107.32816314697266\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 27, loss 107.32816314697266\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 28, loss 107.32816314697266\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 29, loss 107.32816314697266\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 30, loss 107.32816314697266\n",
            "tensor(107.3282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 31, loss 107.32816314697266\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 32, loss 107.3281478881836\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 33, loss 107.3281478881836\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 34, loss 107.3281478881836\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 35, loss 107.3281478881836\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 36, loss 107.3281478881836\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 37, loss 107.3281478881836\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 38, loss 107.3281478881836\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 39, loss 107.3281478881836\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 40, loss 107.3281478881836\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 41, loss 107.32813262939453\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 42, loss 107.32813262939453\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 43, loss 107.32813262939453\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 44, loss 107.32813262939453\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 45, loss 107.32813262939453\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 46, loss 107.32813262939453\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 47, loss 107.328125\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 48, loss 107.328125\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 49, loss 107.328125\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 50, loss 107.328125\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 51, loss 107.328125\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 52, loss 107.328125\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 53, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 54, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 55, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 56, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 57, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 58, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 59, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 60, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 61, loss 107.32809448242188\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 62, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 63, loss 107.32809448242188\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 64, loss 107.32810974121094\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 65, loss 107.32809448242188\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 66, loss 107.32809448242188\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 67, loss 107.32809448242188\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 68, loss 107.32809448242188\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 69, loss 107.32809448242188\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 70, loss 107.32809448242188\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 71, loss 107.32808685302734\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 72, loss 107.32808685302734\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 73, loss 107.32808685302734\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 74, loss 107.32808685302734\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 75, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 76, loss 107.32808685302734\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 77, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 78, loss 107.32808685302734\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 79, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 80, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 81, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 82, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 83, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 84, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 85, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 86, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 87, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 88, loss 107.32807159423828\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 89, loss 107.32805633544922\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 90, loss 107.32805633544922\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 91, loss 107.32805633544922\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 92, loss 107.32805633544922\n",
            "tensor(107.3281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 93, loss 107.32805633544922\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 94, loss 107.32804870605469\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 95, loss 107.32804870605469\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 96, loss 107.32804870605469\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 97, loss 107.32804870605469\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 98, loss 107.32804870605469\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 99, loss 107.32804870605469\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 100, loss 107.32804870605469\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 101, loss 107.32803344726562\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 102, loss 107.32803344726562\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 103, loss 107.32804870605469\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 104, loss 107.32803344726562\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 105, loss 107.32803344726562\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 106, loss 107.32803344726562\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 107, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 108, loss 107.32803344726562\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 109, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 110, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 111, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 112, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 113, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 114, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 115, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 116, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 117, loss 107.32801055908203\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 118, loss 107.32801055908203\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 119, loss 107.32801055908203\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 120, loss 107.3280258178711\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 121, loss 107.32801055908203\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 122, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 123, loss 107.32801055908203\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 124, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 125, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 126, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 127, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 128, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 129, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 130, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 131, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 132, loss 107.32798767089844\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 133, loss 107.32799530029297\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 134, loss 107.32798767089844\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 135, loss 107.32798767089844\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 136, loss 107.32798767089844\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 137, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 138, loss 107.32798767089844\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 139, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 140, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 141, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 142, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 143, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 144, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 145, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 146, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 147, loss 107.32797241210938\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 148, loss 107.32795715332031\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 149, loss 107.32795715332031\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 150, loss 107.32795715332031\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 151, loss 107.32795715332031\n",
            "tensor(107.3280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 152, loss 107.32795715332031\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 153, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 154, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 155, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 156, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 157, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 158, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 159, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 160, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 161, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 162, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 163, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 164, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 165, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 166, loss 107.32793426513672\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 167, loss 107.32794952392578\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 168, loss 107.32793426513672\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 169, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 170, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 171, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 172, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 173, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 174, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 175, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 176, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 177, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 178, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 179, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 180, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 181, loss 107.32791900634766\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 182, loss 107.32791137695312\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 183, loss 107.32791137695312\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 184, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 185, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 186, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 187, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 188, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 189, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 190, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 191, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 192, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 193, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 194, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 195, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 196, loss 107.32789611816406\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 197, loss 107.32788848876953\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 198, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 199, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 200, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 201, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 202, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 203, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 204, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 205, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 206, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 207, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 208, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 209, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 210, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 211, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 212, loss 107.32787322998047\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 213, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 214, loss 107.3278579711914\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 215, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 216, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 217, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 218, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 219, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 220, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 221, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 222, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 223, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 224, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 225, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 226, loss 107.32785034179688\n",
            "tensor(107.3279, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 227, loss 107.32785034179688\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 228, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 229, loss 107.32783508300781\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 230, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 231, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 232, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 233, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 234, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 235, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 236, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 237, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 238, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 239, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 240, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 241, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 242, loss 107.32781219482422\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 243, loss 107.32781982421875\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 244, loss 107.32781219482422\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 245, loss 107.32781219482422\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 246, loss 107.32781219482422\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 247, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 248, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 249, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 250, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 251, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 252, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 253, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 254, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 255, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 256, loss 107.3277816772461\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 257, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 258, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 259, loss 107.3277816772461\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 260, loss 107.32779693603516\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 261, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 262, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 263, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 264, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 265, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 266, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 267, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 268, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 269, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 270, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 271, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 272, loss 107.32777404785156\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 273, loss 107.3277587890625\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 274, loss 107.32777404785156\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 275, loss 107.32774353027344\n",
            "tensor(107.3278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 276, loss 107.3277587890625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 277, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 278, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 279, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 280, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 281, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 282, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 283, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 284, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 285, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 286, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 287, loss 107.32774353027344\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 288, loss 107.3277359008789\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 289, loss 107.3277359008789\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 290, loss 107.3277359008789\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 291, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 292, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 293, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 294, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 295, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 296, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 297, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 298, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 299, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 300, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 301, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 302, loss 107.32771301269531\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 303, loss 107.32772064208984\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 304, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 305, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 306, loss 107.32771301269531\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 307, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 308, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 309, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 310, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 311, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 312, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 313, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 314, loss 107.32768249511719\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 315, loss 107.32769775390625\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 316, loss 107.32768249511719\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 317, loss 107.32768249511719\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 318, loss 107.32768249511719\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 319, loss 107.32768249511719\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 320, loss 107.32768249511719\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 321, loss 107.32767486572266\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 322, loss 107.32767486572266\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 323, loss 107.32767486572266\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 324, loss 107.32767486572266\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 325, loss 107.32767486572266\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 326, loss 107.32767486572266\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 327, loss 107.32767486572266\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 328, loss 107.32767486572266\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 329, loss 107.32767486572266\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 330, loss 107.3276596069336\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 331, loss 107.3276596069336\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 332, loss 107.3276596069336\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 333, loss 107.3276596069336\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 334, loss 107.3276596069336\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 335, loss 107.3276596069336\n",
            "tensor(107.3277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 336, loss 107.3276596069336\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 337, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 338, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 339, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 340, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 341, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 342, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 343, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 344, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 345, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 346, loss 107.32763671875\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 347, loss 107.32764434814453\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 348, loss 107.32763671875\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 349, loss 107.32763671875\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 350, loss 107.32763671875\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 351, loss 107.32763671875\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 352, loss 107.32763671875\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 353, loss 107.32762145996094\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 354, loss 107.32762145996094\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 355, loss 107.32762145996094\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 356, loss 107.32762145996094\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 357, loss 107.32762145996094\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 358, loss 107.32762145996094\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 359, loss 107.32762145996094\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 360, loss 107.32762145996094\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 361, loss 107.32760620117188\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 362, loss 107.32760620117188\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 363, loss 107.32760620117188\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 364, loss 107.32760620117188\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 365, loss 107.32760620117188\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 366, loss 107.32760620117188\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 367, loss 107.32759857177734\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 368, loss 107.32760620117188\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 369, loss 107.32759857177734\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 370, loss 107.32759857177734\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 371, loss 107.32759857177734\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 372, loss 107.32759857177734\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 373, loss 107.32759857177734\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 374, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 375, loss 107.32759857177734\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 376, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 377, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 378, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 379, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 380, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 381, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 382, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 383, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 384, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 385, loss 107.32757568359375\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 386, loss 107.32758331298828\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 387, loss 107.32757568359375\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 388, loss 107.32757568359375\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 389, loss 107.32757568359375\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 390, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 391, loss 107.32757568359375\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 392, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 393, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 394, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 395, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 396, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 397, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 398, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 399, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 400, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 401, loss 107.32756042480469\n",
            "tensor(107.3276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 402, loss 107.32756042480469\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 403, loss 107.32754516601562\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 404, loss 107.32754516601562\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 405, loss 107.32754516601562\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 406, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 407, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 408, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 409, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 410, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 411, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 412, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 413, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 414, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 415, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 416, loss 107.32752227783203\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 417, loss 107.3275375366211\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 418, loss 107.32752227783203\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 419, loss 107.32752227783203\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 420, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 421, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 422, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 423, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 424, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 425, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 426, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 427, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 428, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 429, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 430, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 431, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 432, loss 107.32750701904297\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 433, loss 107.32749938964844\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 434, loss 107.32749938964844\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 435, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 436, loss 107.32749938964844\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 437, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 438, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 439, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 440, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 441, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 442, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 443, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 444, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 445, loss 107.32746887207031\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 446, loss 107.32748413085938\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 447, loss 107.32746887207031\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 448, loss 107.32746887207031\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 449, loss 107.32746887207031\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 450, loss 107.32746887207031\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 451, loss 107.32746887207031\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 452, loss 107.32746887207031\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 453, loss 107.32746124267578\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 454, loss 107.32746124267578\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 455, loss 107.32746124267578\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 456, loss 107.32746124267578\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 457, loss 107.32746124267578\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 458, loss 107.32744598388672\n",
            "tensor(107.3275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 459, loss 107.32746124267578\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 460, loss 107.32744598388672\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 461, loss 107.32744598388672\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 462, loss 107.32744598388672\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 463, loss 107.32744598388672\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 464, loss 107.32744598388672\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 465, loss 107.32744598388672\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 466, loss 107.32744598388672\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 467, loss 107.32744598388672\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 468, loss 107.32743835449219\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 469, loss 107.32744598388672\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 470, loss 107.32743835449219\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 471, loss 107.32743835449219\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 472, loss 107.32743835449219\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 473, loss 107.32743835449219\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 474, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 475, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 476, loss 107.32743835449219\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 477, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 478, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 479, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 480, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 481, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 482, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 483, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 484, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 485, loss 107.32742309570312\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 486, loss 107.32740783691406\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 487, loss 107.32740783691406\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 488, loss 107.32740783691406\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 489, loss 107.32740783691406\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 490, loss 107.32740783691406\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 491, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 492, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 493, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 494, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 495, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 496, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 497, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 498, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 499, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 500, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 501, loss 107.32740020751953\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 502, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 503, loss 107.32738494873047\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 504, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 505, loss 107.32738494873047\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 506, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 507, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 508, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 509, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 510, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 511, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 512, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 513, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 514, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 515, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 516, loss 107.3273696899414\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 517, loss 107.32736206054688\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 518, loss 107.32736206054688\n",
            "tensor(107.3274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 519, loss 107.32736206054688\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 520, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 521, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 522, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 523, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 524, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 525, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 526, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 527, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 528, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 529, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 530, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 531, loss 107.32734680175781\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 532, loss 107.32733154296875\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 533, loss 107.32733154296875\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 534, loss 107.32733154296875\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 535, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 536, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 537, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 538, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 539, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 540, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 541, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 542, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 543, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 544, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 545, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 546, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 547, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 548, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 549, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 550, loss 107.32732391357422\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 551, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 552, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 553, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 554, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 555, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 556, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 557, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 558, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 559, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 560, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 561, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 562, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 563, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 564, loss 107.32730102539062\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 565, loss 107.32728576660156\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 566, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 567, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 568, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 569, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 570, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 571, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 572, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 573, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 574, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 575, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 576, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 577, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 578, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 579, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 580, loss 107.3272705078125\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 581, loss 107.32726287841797\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 582, loss 107.3272476196289\n",
            "tensor(107.3273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 583, loss 107.32726287841797\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 584, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 585, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 586, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 587, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 588, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 589, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 590, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 591, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 592, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 593, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 594, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 595, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 596, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 597, loss 107.3272476196289\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 598, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 599, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 600, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 601, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 602, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 603, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 604, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 605, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 606, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 607, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 608, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 609, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 610, loss 107.32722473144531\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 611, loss 107.32720947265625\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 612, loss 107.32720947265625\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 613, loss 107.32720947265625\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 614, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 615, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 616, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 617, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 618, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 619, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 620, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 621, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 622, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 623, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 624, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 625, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 626, loss 107.32719421386719\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 627, loss 107.32718658447266\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 628, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 629, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 630, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 631, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 632, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 633, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 634, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 635, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 636, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 637, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 638, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 639, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 640, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 641, loss 107.3271713256836\n",
            "tensor(107.3272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 642, loss 107.32715606689453\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 643, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 644, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 645, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 646, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 647, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 648, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 649, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 650, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 651, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 652, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 653, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 654, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 655, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 656, loss 107.32713317871094\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 657, loss 107.3271484375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 658, loss 107.32713317871094\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 659, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 660, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 661, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 662, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 663, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 664, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 665, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 666, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 667, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 668, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 669, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 670, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 671, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 672, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 673, loss 107.3271255493164\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 674, loss 107.32711029052734\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 675, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 676, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 677, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 678, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 679, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 680, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 681, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 682, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 683, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 684, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 685, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 686, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 687, loss 107.32709503173828\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 688, loss 107.32708740234375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 689, loss 107.32708740234375\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 690, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 691, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 692, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 693, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 694, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 695, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 696, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 697, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 698, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 699, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 700, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 701, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 702, loss 107.32707214355469\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 703, loss 107.32705688476562\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 704, loss 107.3270492553711\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 705, loss 107.32705688476562\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 706, loss 107.3270492553711\n",
            "tensor(107.3271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 707, loss 107.32705688476562\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 708, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 709, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 710, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 711, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 712, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 713, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 714, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 715, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 716, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 717, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 718, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 719, loss 107.32703399658203\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 720, loss 107.3270492553711\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 721, loss 107.32703399658203\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 722, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 723, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 724, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 725, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 726, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 727, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 728, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 729, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 730, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 731, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 732, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 733, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 734, loss 107.32701110839844\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 735, loss 107.32701873779297\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 736, loss 107.32701110839844\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 737, loss 107.32701110839844\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 738, loss 107.32701110839844\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 739, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 740, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 741, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 742, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 743, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 744, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 745, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 746, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 747, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 748, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 749, loss 107.32699584960938\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 750, loss 107.32698822021484\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 751, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 752, loss 107.32698822021484\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 753, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 754, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 755, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 756, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 757, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 758, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 759, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 760, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 761, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 762, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 763, loss 107.32697296142578\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 764, loss 107.32695770263672\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 765, loss 107.32695770263672\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 766, loss 107.32695770263672\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 767, loss 107.32695770263672\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 768, loss 107.32695007324219\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 769, loss 107.32695007324219\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 770, loss 107.32695007324219\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 771, loss 107.32695007324219\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 772, loss 107.32695007324219\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 773, loss 107.32695007324219\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 774, loss 107.32695007324219\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 775, loss 107.32695007324219\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 776, loss 107.32695007324219\n",
            "tensor(107.3270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 777, loss 107.32695007324219\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 778, loss 107.32693481445312\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 779, loss 107.32693481445312\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 780, loss 107.32693481445312\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 781, loss 107.32693481445312\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 782, loss 107.32693481445312\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 783, loss 107.32693481445312\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 784, loss 107.32693481445312\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 785, loss 107.32691955566406\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 786, loss 107.32691955566406\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 787, loss 107.32691955566406\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 788, loss 107.32691955566406\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 789, loss 107.32691955566406\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 790, loss 107.32691955566406\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 791, loss 107.32691955566406\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 792, loss 107.32691955566406\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 793, loss 107.32691955566406\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 794, loss 107.32691192626953\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 795, loss 107.32691192626953\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 796, loss 107.32691192626953\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 797, loss 107.32691192626953\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 798, loss 107.32689666748047\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 799, loss 107.32691192626953\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 800, loss 107.32689666748047\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 801, loss 107.32689666748047\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 802, loss 107.32689666748047\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 803, loss 107.32689666748047\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 804, loss 107.32689666748047\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 805, loss 107.32689666748047\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 806, loss 107.32689666748047\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 807, loss 107.3268814086914\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 808, loss 107.3268814086914\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 809, loss 107.3268814086914\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 810, loss 107.3268814086914\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 811, loss 107.3268814086914\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 812, loss 107.32687377929688\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 813, loss 107.3268814086914\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 814, loss 107.32687377929688\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 815, loss 107.3268814086914\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 816, loss 107.32687377929688\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 817, loss 107.32687377929688\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 818, loss 107.32687377929688\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 819, loss 107.32687377929688\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 820, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 821, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 822, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 823, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 824, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 825, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 826, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 827, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 828, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 829, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 830, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 831, loss 107.32685852050781\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 832, loss 107.32685089111328\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 833, loss 107.32685089111328\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 834, loss 107.32685089111328\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 835, loss 107.32685089111328\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 836, loss 107.32685089111328\n",
            "tensor(107.3269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 837, loss 107.32685089111328\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 838, loss 107.32683563232422\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 839, loss 107.32683563232422\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 840, loss 107.32683563232422\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 841, loss 107.32683563232422\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 842, loss 107.32683563232422\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 843, loss 107.32683563232422\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 844, loss 107.32683563232422\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 845, loss 107.32683563232422\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 846, loss 107.32682037353516\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 847, loss 107.32682037353516\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 848, loss 107.32682037353516\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 849, loss 107.32682037353516\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 850, loss 107.32682037353516\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 851, loss 107.32682037353516\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 852, loss 107.32682037353516\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 853, loss 107.32682037353516\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 854, loss 107.32681274414062\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 855, loss 107.32681274414062\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 856, loss 107.32681274414062\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 857, loss 107.32681274414062\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 858, loss 107.32681274414062\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 859, loss 107.32681274414062\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 860, loss 107.32681274414062\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 861, loss 107.32679748535156\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 862, loss 107.32679748535156\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 863, loss 107.32679748535156\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 864, loss 107.32679748535156\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 865, loss 107.32679748535156\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 866, loss 107.32679748535156\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 867, loss 107.32679748535156\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 868, loss 107.32679748535156\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 869, loss 107.3267822265625\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 870, loss 107.3267822265625\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 871, loss 107.3267822265625\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 872, loss 107.3267822265625\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 873, loss 107.3267822265625\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 874, loss 107.3267822265625\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 875, loss 107.3267822265625\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 876, loss 107.32677459716797\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 877, loss 107.3267822265625\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 878, loss 107.32677459716797\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 879, loss 107.32677459716797\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 880, loss 107.32677459716797\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 881, loss 107.32677459716797\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 882, loss 107.32677459716797\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 883, loss 107.32677459716797\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 884, loss 107.32677459716797\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 885, loss 107.3267593383789\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 886, loss 107.3267593383789\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 887, loss 107.3267593383789\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 888, loss 107.3267593383789\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 889, loss 107.3267593383789\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 890, loss 107.3267593383789\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 891, loss 107.32674407958984\n",
            "tensor(107.3268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 892, loss 107.3267593383789\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 893, loss 107.32674407958984\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 894, loss 107.32674407958984\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 895, loss 107.32674407958984\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 896, loss 107.32674407958984\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 897, loss 107.32674407958984\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 898, loss 107.32674407958984\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 899, loss 107.32674407958984\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 900, loss 107.32674407958984\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 901, loss 107.32674407958984\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 902, loss 107.32673645019531\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 903, loss 107.32673645019531\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 904, loss 107.32673645019531\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 905, loss 107.32673645019531\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 906, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 907, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 908, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 909, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 910, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 911, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 912, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 913, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 914, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 915, loss 107.32671356201172\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 916, loss 107.32672119140625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 917, loss 107.32671356201172\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 918, loss 107.32671356201172\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 919, loss 107.32671356201172\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 920, loss 107.32671356201172\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 921, loss 107.32671356201172\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 922, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 923, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 924, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 925, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 926, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 927, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 928, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 929, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 930, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 931, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 932, loss 107.32669830322266\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 933, loss 107.3266830444336\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 934, loss 107.3266830444336\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 935, loss 107.3266830444336\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 936, loss 107.3266830444336\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 937, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 938, loss 107.3266830444336\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 939, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 940, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 941, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 942, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 943, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 944, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 945, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 946, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 947, loss 107.32667541503906\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 948, loss 107.32666015625\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 949, loss 107.32667541503906\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 950, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 951, loss 107.32664489746094\n",
            "tensor(107.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 952, loss 107.32666015625\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 953, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 954, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 955, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 956, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 957, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 958, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 959, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 960, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 961, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 962, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 963, loss 107.32664489746094\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 964, loss 107.3266372680664\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 965, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 966, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 967, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 968, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 969, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 970, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 971, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 972, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 973, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 974, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 975, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 976, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 977, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 978, loss 107.32662200927734\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 979, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 980, loss 107.32660675048828\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 981, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 982, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 983, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 984, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 985, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 986, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 987, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 988, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 989, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 990, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 991, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 992, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 993, loss 107.32659912109375\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 994, loss 107.32658386230469\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 995, loss 107.32656860351562\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 996, loss 107.32658386230469\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 997, loss 107.32656860351562\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 998, loss 107.32658386230469\n",
            "tensor(107.3266, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "epoch 999, loss 107.32656860351562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "07k5Y07qYHWn",
        "outputId": "9b45dbe1-3ba6-417c-9e66-48daa552138b"
      },
      "source": [
        "# plot predicted versus actual\n",
        "with torch.no_grad(): \n",
        "  predicted = model(Variable(torch.from_numpy(x_test).cuda())).cpu().data.numpy()\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(x_test, y_test, 'go', label='Actual Height', alpha=0.5)\n",
        "plt.plot(x_test, predicted, '--', label='Predicted Height', alpha=0.5)\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe8107d1e10>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eXRcZ5Xu/TtDnRpVmgdbsmzHsWJbxkPiDDaJM5KEBgIJhKEbbqcT4Iahabqb+60eVtPmBu6i6TRwISuBAFkMfdsNnYQ4BEIHExxnsCEmcRQP8hBZsmaVpJqrTp3x++O4jkvzYNlSlHq8vGyd8a2jU/vd77P3frZg2zZFFFFEEUUsLojzPYAiiiiiiCLmHkXjXkQRRRSxCFE07kUUUUQRixBF415EEUUUsQhRNO5FFFFEEYsQ8nwPAKCqqspesWLFfA+jiCKKKOJNhT/+8Y+Dtm1Xj7dvQRj3FStWcODAgfkeRhFFFFHEmwqCIHRMtK9IyxRRRBFFLEIUjXsRRRRRxCJE0bgXUUQRRSxCLAjOfTzouk5XVxeqqs73UIqYQ/h8PhoaGvB4PPM9lCKKWNRYsMa9q6uLkpISVqxYgSAI8z2cIuYAtm0zNDREV1cXK1eunO/hFFHEosaCNe6qqhYN+yKDIAhUVlYSiUTmeyhFFDElWvpaeLz1cU7HT9NY2sgda+5gQ92G+R7WtLGgOfeiYV98KP5Oi3gzoKWvhfv33U80G6Uh3EA0G+X+fffT0tcy30ObNhas515EEUUUUYgL6Uk/3vo45b5yyv3lAO6/j7c+/qbx3he0574Q8MQTTyAIAq2trVMe+81vfpNMJjPre/3whz/ks5/97LS2X3fddVMWfn384x/nyJEjkx5z11138eijj47Z3t7ezn/8x39MY9RFFHH+caE96dPx05T6SkdsK/WVcjp++rzc73xg0Rj3lr4WduzZwd277mbHnh1z9kvfuXMnV199NTt37pzy2HM17nON73//+6xbt25W5xaNexELCYWetCiIlPvLKfeV83jr4+flfo2ljcTV+IhtcTVOY2njebnf+cCiMO7na1ZPpVK88MIL/OAHP+A///M/3e2mafKFL3yB9evXs2HDBr797W/zrW99i56eHq6//nquv/56AEKhkHvOo48+yl133QXAL37xC6688ko2b97MTTfdRH9//zmN85lnnmHr1q1ceuml3HnnnaRSKWCkd/+DH/yApqYmrrjiCj7xiU+MWAns3buXbdu2cdFFF7le/N/93d/x/PPPs2nTJr7xjW+c0/iKKOJccaE96TvW3EFUjRLNRrFsi2g2SlSNcseaO87L/c4HFgXnfr74sV27dnHrrbfS1NREZWUlf/zjH7nssst4+OGHaW9v5+DBg8iyzPDwMBUVFXz961/nd7/7HVVVVZNe9+qrr2b//v0IgsD3v/99vva1r/Fv//Zvk57z05/+lBdeeMH9+eTJkwAMDg7y5S9/md27dxMMBvmXf/kXvv71r/PFL37RPbanp4f77ruPV155hZKSEm644QY2btzo7u/t7eWFF16gtbWV2267jQ984AN89atf5f777+epp56azaMr4k2OhZYp0ljaSDQbdb/bcH496Q11G/jC1i+MeAb3bL7nTcO3wyIx7qfjp2kIN4zYNhez+s6dO/mrv/orAD784Q+zc+dOLrvsMnbv3s29996LLDuPr6KiYkbX7erq4kMf+hC9vb1omjatnO8PfehDPPDAA+7P1113HQD79+/nyJEjvP3tbwdA0zS2bt064tw//OEPXHvtte4477zzTo4fP+7uf9/73ocoiqxbt+6cVxFFvDmQN94Hew8Sy8Uo85axackm1zO9f9/9lPvKR6yEv7D1C/Nm3O5Ycwf377sfcL7bcTVOVI1yz+Z7zts9N9RteFMZ89FYFMb9fMzqw8PDPPvss7z++usIgoBpmgiCwL/+679O+xqFaX+FlbZ/+Zd/yd/8zd9w2223sWfPHnbs2DHrcdq2zTve8Y5pxQQmgtfrHXG9IhY38jSmaZm0RdsQBZHh7DABT4D7991P0BOc8Ur4fHv6i8GTvtBYFJz7+eDHHn30UT72sY/R0dFBe3s7nZ2drFy5kueff553vOMdfPe738UwDMCZCABKSkpIJpPuNWprazl69CiWZfHzn//c3R6Px6mvrwfgRz/60azHCHDVVVfx4osvujRNOp0e4ZUDXH755Tz33HNEo1EMw+Cxxx6b8rqjP0sRiwd5GrM72Y3f46fMX4Zf9tOT6qHcV87+rv0z4rcvVCbLhroN7LhuB4+89xF2XLejaNinwKIw7vlZvdxfTleii3J/+TkvIXfu3Mntt98+Ytv73/9+du7cycc//nEaGxvZsGEDGzdudLNKPvnJT3Lrrbe6AdWvfvWrvPvd72bbtm0sWbLEvc6OHTu48847ueyyy6bk56dCdXU1P/zhD/nIRz7Chg0b2Lp165i0zfr6ev7hH/6BK664gre//e2sWLGC0tLSCa7oYMOGDUiSxMaNG4sB1UWGfHAyrsbxyT4AfLKPuBqn1FeKjT2jTJELnclSxPQgLIRl+JYtW+zROdtHjx5l7dq18zSixYdUKkUoFMIwDG6//XbuvvvuMZPXhULxdzt/aOlr4XO//hwD6QEyeoYSpYTKQCVZPYvf42dj7UZyZo6MnqHcVz6C357IYbp71900hBsQhbO+omVbdCW6eOS9j1zIj/eWgyAIf7Rte8t4+xaF517E1NixYwebNm1i/fr1rFy5kve9733zPaQiLjDy9MnS0FJkUcYreemMd9Kb7CVrZFkaWkpUjfLpLZ+e0Up4MeSEL0YsioBqEVPj/vvvn+8hFDHPKKRPwr4wrYOt6JZOzsyxtmotTVVNIwKh06U15yOTpYipUTTuRRTxFkFhynBdqI66UN2c0Cdv1kyWhZbLP9coGvciiniL4HwWAr3ZcsLzFNVCyuWfaxSNexFFLABcCC+ySJ+cxWJQfZwKxYBqEUXMMy5knng+UNrS18Jr/a+RUBM83vr4m0anfK4EAheD6uNUKBr3SSBJkpthcuedd56T4mOhtO5UUrx79uzhpZdemvE9VqxYweDg4JTb9+zZw7vf/e5Jr3XgwAE+97nPTXpMe3s769evH3ffD3/4Q3p6eqYx6iJmkyc+WyO3oW4Dd6y5g7AvzMbajWyo2/CmaUQxl5PgWyHDZ0rjLgjCI4IgDAiCcGjU9r8UBKFVEITDgiB8rWD73wuCcFIQhGOCINxyPgZ9oeD3+zl48CCHDh1CURS+853vjNifr1CdKaaS4p2tcZ9LbNmyhW9961uzPr9o3KePmXqR52rkzrXo6HzJa0+FuSyWWgyqj1NhOp77D4FbCzcIgnA98F5go23bzcD9Z7avAz4MNJ8550FBEKS5HPB84ZprruHkyZPs2bOHa665httuu41169Zhmib/63/9Ly6//HI2bNjAd7/7XcDRaPnsZz/LJZdcwk033cTAwIB7rUIp3l//+tdceumlbNy4kRtvvJH29na+853v8I1vfINNmzbx/PPPE4lEeP/738/ll1/O5ZdfzosvvgjA0NAQN998M83NzXz84x+flS5MOp3m7rvv5oorrmDz5s3s2rULGOndRyIR3vGOd7j3Wb58ubsSME2TT3ziEzQ3N3PzzTeTzWZ59NFHOXDgAH/2Z3/Gpk2byGazs3/wbwFM5EV6Je+4RvRcjdy5UBLz2X5uLqmU81HVvtAwZUDVtu29giCsGLX5U8BXbdvOnTkmb7neC/znme2nBEE4CVwB7DvXgf7Xgc4x25pqS9i4rAzdtHji1e4x+9ctDdO8tJSsZvJUy0gv8s4ty6Z9b8MwePrpp7n1VmeOe+WVVzh06BArV67k4YcfprS0lJdffplcLsfb3/52br75Zl599VWOHTvGkSNH6O/vZ926ddx9990jrhuJRPjEJz7B3r17WblypSsdfO+99xIKhfjCF74AwJ/+6Z/y13/911x99dWcPn2aW265haNHj/KlL32Jq6++mi9+8Yv88pe/5Ac/+MGEn+H6669Hkpx5NpVKsWbNGgC+8pWvcMMNN/DII48Qi8W44ooruOmmm0ac+6UvfYkbbriBv//7v+fXv/71iPucOHGCnTt38r3vfY8PfvCDPPbYY3z0ox/lgQce4P7772fLlnGL54oowHiBzrZoGzY2iqSMyeY4VxXU2WTN5AO+u1p3oUgKm5dsdicWuDCByLnO9nmzZfjMFLPNlmkCrhEE4SuACnzBtu2XgXpgf8FxXWe2vSmRzWbZtGkT4Hju99xzDy+99BJXXHGFK9P7zDPP0NLS4vLp8XicEydOsHfvXj7ykY8gSRJLly7lhhtuGHP9/fv3s337dvdaE0kH7969ewRHn0gkSKVS7N27l8cfd7y1d73rXZSXl497PjBCZ37Pnj1uUdMzzzzDk08+6f6sqiqnT480Ei+88IIrfHbrrbeOuM/KlSvdZ3TZZZfR3t4+4RiKGB95L/KhAw/xi2O/wMZGFmSaKpvGzeY4VyM306yZwrRB27axsdnXtY+tDVupC9XNSSByOtlCxWyfmWG2xl0GKoCrgMuBnwmCcNFMLiAIwieBTwI0Nk79Uk7maXskcdL9fkWakafunneGcx+NYDDo/t+2bb797W9zyy0jwwu/+tWvZny/iWBZFvv378fn883ZNfOwbZvHHnuMSy65ZMT26eq6F8oFS5JUpGDOAWk9zbrqdXQlujjYd5DORCe6pdNc0wyc9c4/f+Xnz8nIzbToqJAGKvOXkdWz+CQfrYOt1IXqzjkQOd2c8zdrsdR8YbbZMl3A47aDPwAWUAV0A4VWtOHMtjGwbfth27a32La9pbq6epbDmH/ccsstPPTQQ+i6DsDx48dJp9Ns376dn/70p5imSW9vL7/73e/GnHvVVVexd+9eTp06BUwsHXzzzTfz7W9/2/05P+Fs377dVaR8+umniUajsxr/t7/9bZevf/XVV8cc8/a3v52f/exngOPpT+c+RcngmeHx1scxLZNDA4dQDZUyfxmWZbG3Yy/9KWeizRvRifhiYNqBzpnI5xZy3Wur1qIaKrZtE1NjcxKInEkMoSj7O33M1nN/Arge+J0gCE2AAgwCTwL/IQjC14GlwGrgD3Mx0IWKj3/847S3t3PppZdi2zbV1dU88cQT3H777Tz77LOsW7eOxsbGMd2RwJHrffjhh7njjjuwLIuamhp+85vf8J73vIcPfOAD7Nq1y+3P+pnPfIYNGzZgGAbbt2/nO9/5Dv/8z//MRz7yEZqbm9m2bdu0VkCj8U//9E98/vOfZ8OGDViWxcqVK8e01svf5yc/+Qlbt26lrq6OkpISt1freLjrrru499578fv97Nu3D7/fP+OxvZVwOn6arkQXPtmH3+OnOlDNaf00uqVzJHIERVJGeOej+eK5rrgspEnaom3kjByrK1dTG6pl27JtvHD6BSKZCM91PMfqitU8dOAhcmZuVgVY56uT2lsdU0r+CoKwE7gOxzPvB/4Z+AnwCLAJ0HA492fPHP+PwN2AAXzetu2npxpEUfJ3YSOXyyFJErIss2/fPj71qU+NS1dNF8Xf7Vjs2LODnx3+GdWBareD11BmiKSWxCN5+LO3/dmkRnPHnh1jePj8zzuu2zGjsRROFKW+Uk4OnWR/9362NmxlVcUq3hh+g31d+7iq/ipKvCXs7dgLwPbl2/HJvknlgc/32N9qmEzydzrZMh+ZYNdHJzj+K8BXpj+8IhY6Tp8+zQc/+EEsy0JRFL73ve/NyzgWs9DTHWvu4OetP3cbZqiGiiiKbGvYRlNV0wgjN95zmEvvd3RpflNVEwDdyW68spfuZDdX1V9FU1UTe9r3EPaGATg2dIzrVlznXiP/71S/r/kOlC7W96rYrKOIC47Z/G5He5P5dMH6cD2aqS2KL+Wjhx/lvr33oVs61cFq6kP1yJI8wgsez6s+HDlMzsxR6i1l85LN1IXqgMm938kM2lTNNwr372rd5Rr3RC7Be9e8F8u2aOlrIewLT7vhx3jjgelNDueC8d6rma485hNv2mYdC2HiKWJuMdvf6eigm2ZqnBw+yau9r17wYprzhQ80f4Cf3P4TPtj8QVaVr6KpqmmMkSl8DgPpAQ4PHkZAIOgJksgleK79OXqTvZMGOqcqRJqqNL9wf36VoRqqG3SNq3G6kl0cGzzG3o697O3Yi2ZqkxZajQ6UAhekWGoxtwhcsKqQPp+PoaEhKisrXQ6yiDc3bNtmaGhoVimdo2mHo4NHKVFK0EztghfTnE9MVVhT+BwO9BxgMDOIaZkAbG/cTke8g993/573rXnfhGmCUykiFtIkqqFysO8gQ9kh3nHRO2jpaxmx/5LKS/jFsV8Qy8XwiB5ODJ2gNlhLJBthSXAJYW+YrJ7lpc6XuKrhqmnTRBdKtXExB3MXrHFvaGigq6uLSCQy30MpYg7h8/loaGiY+sBRGF24E1fjeCTPiHL0hfilnAs+d3TmiqqrhH1h2qJt+CQf0hmFj2NDx7iq4Sp0S5+Uoz/Ye3DMGAqfXT7V8sEDD/LbU7+l0l/JjStvRJEUNwMnn2/+3KnnSOkp/LIfWZQxLINjw8dQRIVT+imCSpCAJ0BcjfP40cdprmmmpa9lymcw2uj2pfo4OniUnqRTaT5XFM351LifbyxY4+7xeNzKzSKKGB10UySFRC7BpUsudY9ZaF/KuUhPzF/DtEy6El10xjt5re81Kv2V+GU/hmWADctKlyEJEgf7DvLO1e+cdAyn4qcIeAJuoBTGPrsNdRuoC9XxrtXvGmH4wPGe8znm17Vfx0VlFyFLMoOZQZJaElVXMQSDMn8ZSTVJb7KXkCeEhcXS0NJxn8HoCcgreYmrccr95fSl+tjXtQ/BFpw+r3PYWGO+g7nnEwuacy+iiDxGF+5cuuRSVlWswit5F6yq34MHHnR5518d/xVPHnuSR488ypU/uJItD2/h0cOPTnmN0cVNy0qXUROsoTvZjSzICIJATbCGoCeIjc1QdmjEMxiPU15fvZ7DkcNEs1F6k708feJpfnnil/Sn+kdw2tMR6upOdiMKolNNa+oYpoGAgGEbVPorMTFBgKSeRBREelI9mJY5gtMeLwbQmeikLdpGNBvl6OBRBFvAxmZd9bo55cUXs4DYgvXciyhiNMYr3FmopegtfS3sbttNhb8CEZHWwVYyRgZFVBAQeGP4DT7/35+nI9ZBUk+6n2F99XoORQ6NoFCiatQtbgKn/+lwdpi6kjo2L9lM62ArcTWOIincdNFNI57Bwd6DRHNREmqCUl8pa6rWsKpiFWktTc7MjUu73NZ0G4cih3il9xUODxymsbSRSCbi3mPzks3u9etL6jkaOYosyngkD5qpYQs2tm3THm/HtEx0S0dEpDZYS1bP8nr/66S1tHuN8fj1VawiZ+Yo95fTk+xhaWgp66rXURuqBeaWglusAmJF417EmxZz8aU8XznODx54kKye5ZR6Ct3SyRk5REQsLAKeAAFPgKyW5Wv7vsaHmz9MQ7iB44PH+fFrP3aLhaLZKKdip0jmkiwrPavqoRoqjaWNDGWH8EpeLqm8xA16Cggup93S18Kp+CkEW6DUV0pWz7Kvax/NVc1sWuKIveVpl/5UP6/1v8bp2Gn+++R/c+PKG7my/kqeOfkMrYOtLAsvI+AJkMgl6E50u/f47OWf5S+e/AsCcgDTdAy5bdsEpAAZI4ONkx0lCAL96X4CSgBREInlYu7nmSio2ZXocmMH0WwUzdTY077HnWQKKbkixqJo3It402I6hnmyY86FE5/suo8efpSfHvoptm2jmRqmZWJgOMbddoy7LMqopopgCrzW/5rL9SqiQneym9WVqyn3l9Nc3cyz7c+OKG5STZXmqmbCvjA9yR6eeeMZdEvHJ/l44fQLdCW6+PONf84DLz9AUk2S1tOYtkmFv4KckeNw5DB/d/Xf8c3ff5OGcANHBo7wXMdzWLaFZmggwOHBw2xt2EplsJKMkWEwO8ia4BouW3oZiqS4WStNlU0sCy+jPdZOzsgBIAkSqqWOeF6mbRJVo2QjWepL6llRtsLdN1VQ8441d/CPz/4jJ4dPUqKU4JE8JHIJOhOd0wrOvlWxYIuYiihiMkyn+GSqY2Zb9j7ZdQE+9vOP0ZfqQxZldEsnpsbQLd3NR68MVKKbOgPpAbyyl+bqZnyyjyORI4iCiF/2s6J8BXE1TtgbJpKKMKQOkTNzlPnKWFu5lupQNbc13cY/PPsPRNIRAp4AADkzhyIphJQQsihT5a8iqkYZyAxQ7i2nNlSLKIhcu+JadrXuwrAMupPdKKKCV/bSn+5HEiRWlq2kKlhFXI1TopQwkB6grqTOHZMoiFxSdQm723bjl/3E1bh7rlfyEtNiI56ZgMOZi4g0ljZyy8W38J13f2fav8t7n7qXV3tfRTM1l15KqAl6Uj1cVH7Roihimw3OSX6giCIWIqaTBz3ZMQBPtD4BQJmvjDVVa8Zok0/knU91Xd3SqfRX0pHowDRNt3DLxka0RVK5FIlcAsM2EEyB0/HT1IfrCSpBYtkYKS1FbaiWsDdMb7KXSCbCtoZtpPQUkUyEnnQP91x6D4cih4hmo/hlPx7J4z6baDZKTI0R9oaJ5+IsCS1hRekK/B4/9SX1HBpwzru4/GJ+efKXqIaKX/Jj2RayKKOICikt5dBJZo62aBuGZWBYBrqt80b0DTRDoyveRUWgAgGBnmQPsihj2ia24OjR29hYtuXo04uy+xx8sg+BkbUrQU+QvR17sbG5quGqMasnzdS45eJb3KrZvlQfhyKHMCyD7cu3z2kGzWJB0bgX8abEdIpPJjrmYO9B2qJteCUvtm27XPTWhq14JS+NpY2TUjZT3dsv++mIdeAVvSTNJLZtIyAQkANkzAyWYSFLMn782NgMZ4eJZqMokkJaT6NICv2pftJ6moyRocpXRdpIc/3K6wE4MXSCB15+gO5kN1k9Cx5QUABHJkA1VXySj/pQPR2JDtqj7VQHqmmLtvFa32vUl9TTm+zl+PBxFEnBMA1yVg7BEKj2V5PW0wxnh/Erfsq8jn47wKnYKTyiB0EQ8Ek+ulJdhH1hSrwliIJI2Bt2jLvtGHPN1LCx8YpeLCws28Ire9m+fDs506FwCp/zey55j+u1j8Zo6qZ1sBURkZpgzYgitgcPPEhdqG7R6cTMBsVUyEWI+WpgfCFRWALfn+pnT/seHj3yKG3RtinL6GO5GOW+ci5dcqlrZLySl1d7X3XTKScrS5+sPL+xtNHhngUwbAOv5MUre/FJPtZUrWFN1RqCSpCwEkaRFRRJwbItDNvAwkJAQDVVelO9rhedNbL0Jfvcz/qH7j9weOAwCTVBzswxnB0eITkgCiJBJUiJr4QVpSswbZMT0ROk9bTr+eY59jJfGaW+Ujyix02nLPeXY2ISlIOUeB2OG8GhViws14PXTI0TwydIaSkCngCGZVAbrCWoBAkqQWRRRhZkREHEK3kp8ZawrnodPtnn8unTLf8f3dB6ID2AZVusrTqrUaQaKrvbds9Lf9eFiCLnvsiwkISQzqfaXmFxz+v9ryMKTibK+ur1rtgWMO6zSKgJNtRtQBRE+lP9HB08SiwbQxAEfvS+H7GhbsOk4ln5Tkj5wqJIJkJKSxFSQqS0FL2JXvweP1nD8XglUWJl6UpsbAbSA6T1NBX+CuK5OFkji4iILDqLaNM2ERHxyl4CngCWbZHW0oiiyJalW+iMd7q55QE5QDwXx7AN14hqloZH8FDiLWFJaAle2cuRwSNYlvNs+tJ95MwcpmUS9oapDlbTHm1HFER8so+ElmB52XIqfBVcs/wa9nbs5cTQCaJqFFmQMWwD3XQyYryyF9MyCSkhynxlxNQY1cFqti/fTjKXZO/pvfgkH0PZIRRJIewNc0X9FUii5KZb/r/X/9+YNMdCkbKJ3qeW/hZyRg5ZlCn1lbK2ai2v9L4CMKKIa76lg8+34uRknLu0Y8eOObvRbPHwww/v+OQnPznfw1gUeOjAQ4DDAwuC4OZGt8fbXTnWC4G88QWoCdYQU2M82/4sq8pXuV/ic0FtqJZV5av42ZGfEclEXEOK4PC3A5kBPrT+Q6wqX0V7vJ3ORCd1oTru2XwP0ZzDSfs9fkJKiBVlK6gN1bJpySYkQeJ/PPE/eLb9WfZ17qM70U1VoIqQEiKmxqgL1fGh9R/CtEwePfIoSS2Jbdn0p/tJqAmH5jGyDs2BgNfjGOmwN+ykBtq2y2VLooRhGi43rUgKPtnR3bGx8Yge55rYeCUvsihzYvgEoiA6dImRdSgQweG6JVHCI3oIe8OU+cvoSnbRm+rFsAwCngC2YJPRM2SNLLqlO//Xs9iCTU2gBkVWWFWxiu+9+3tkjSwxNcbxoeOUeEsYygxh2ZYz+Qgipm3ik3wgOHx4XItTHahGMzUO9h2kLdaGT/ZR4a9geelyqoJVNIYbaa5p5prGa3jy+JOA01owrsbpTHRS4a8Y8ZxHv6+1oVquW3EdK8tW8vvu3zOUGcLv8aObOseHjjOkDnFN4zWUeEvcc7yyl85EJ+9d895zfudmivP9HQD40pe+1Ltjx46Hx9tX5NwXGRaKENKFEH7aULeBMm8Zw8owftmPT/aR1bMc6D3AH3v/OKm3NLrk/I3oG2gRjX998V8xLROv5CVn5TgZPclQZoiaUA1ZI8uldZdy71P3sr9rPz7Zx7Yl23j65NMoooJqqMTVuBsstLCQbAnRFomkIwSVIIqsYKkWmqUhCZKz4rAtRJwsGdM2MTERLIGUlkKSJCr9lSS1JG/E3nDzxn0eHyk9hSiKaIbDbefpj5gaI56LY9s2pm0iILiUjGVb6IaOgVNJKhsyNYEabGwuLr+Yr9zwFTbUbeD40HHue/4+ehI9eEQPlf5K+tP9aJbmZr4k9ASiIBKSQmi2xlB2CMM23OcnCzLt8Xb8sp93Nb2LT2/5tJullH83agI1HBs8hmZo/Er9FVc3Xo0kSmPK/0fr6ywNLeXaFde6BVxhb5igEnQnxzzmU5LiQomfTYSicV9kWChCSBdqkonlYo5hPLNCMW3TTQ30iB6ePvE0/97y71xadyk2NieGTyAgsLpiNQA4NFQAACAASURBVD16D3s79pLW0+SMHIOZQadJhiCSM3MIgoBhGUSyEWzB5trGa3l94HX3Poqo8Nu239KX6kM3dSysEWOzsUkaSbJmFo/kQZIksM5kixgCOSvnpgf6ZB9pLU1QCYLtrD7Sehqv5CWlpVgWXkYkHQELNEsjo2fA5iz1I0iYpknMiOVv7kJAwLTNEYVDAB7R43ROykWpV+qpD9cD8KmnPsVv2n6DX/ZT5a+iN90LNpT7yhnODqPbuntdRVRIGkl3otJNHY/kIWfm6E52E/aGsWyLV3tfHRGQ9ogenjr2FG3RNiRRQpEV4rk4L/e8zMbajXzxd18klotR5i2jrqSO7kQ3F5VfREO4gf1d+xnODrNt2TbXu89ryOeDsQtBJ2a+Ha2icV9kWChCSBNNMl7Jy449O+aMgyzzljGcGWYoM0RCSxBJR7BtG7/Hz+/af0daS5PRM+xq3YUkSgSVILZtcyp6Cq/s5caVN3Js6BiRdATVUB2v1LbJ2Q6tkvdSDcvgVPyU25iiP91PRs8wrA6Pa9gLIQoiIU+IgCdAJB1xK1VlQXa8eyQyRgYLC4/pob6knpyZI6Wn0CyNVeWrqAw43rtu6li6RdbIYtqO1K+AgCIpZ6mpUZhobLrlGOKLwhfhk30cixzjY098zPXW/bIfxaNw+ZLL2d+935kcBJBt2Q2wmrY5ogrVtJ1Vh27p7mc3bRPN1DBMg8/9+nP0pnrpS/a5x0iWhCRILC1Zio1N62ArAgKiIDKcHeaN6BsYluHGQGqCNcSyMVoHW93GJHE1zqYlm9xg+GhJivnotjTfjlbRuC8y5IWQ5ltzZX31eu57/j50U6c6UE1DuIFEzuGPFUmZkybOAJuWbEI3dQ70HcCynGwTv+wnmo2S1tKEvCGnQvRMIBAdqgPVDGWGUHMqx4eP053sxi/7SetpDMtwjdWIf204PHAYSZSwbRuP5CGajZIzc5Ma9rwBrA3V0pvsRZEUhrJD7rUBR1wLCEpBwt4wsVyMumAdpd5STkRP0JfqoyfZQ1pPo5tOJaoiKkiChGVb+GU/KW3iZuUTwcYmqkZZElpCZ7yTtJ6mzFdGSkthWAYDmQECngBdcadxd4AAcS2OJTjZPQCCfXYCtGzLTXnMYygzhCw5UsA9yR4CngA+yedOTj7R5/D/Voa2WBuV/kpUQ+XiioudoLSepSPeQWO4kaODR6kN1bK2ai0vnn7RzZgpdGDGk6QYndZ6YugEH3viY6wsXelOCNN5/2Y6Qcy3o1XMlilizpH/MhmmQXeqm0g6gkf00FTZxNKSpXPaCLmlr4WPPfExVz/lZPQkOSNHMpdEkRQqA5UMpAccmsUWEEWRpSVLnSYXpkmp31E9lASJnJFjSB0acw8Jx7M0cbhkAMMy3JzuqYy7KIgEPUGSWtJNJxzvOIC6YB0ZPYNhG9SX1LtNsvMVrpIgYWGhiArrqtcRV+NEMhFnYjpjcGeCkCeER/SQNbJnPxM2kiC56o4e0UOZt8wt+8/oGURBxMZGEAQsyylUyht515M/85kEBDyix6m+PUOfiYJIPBfHtJxAsICAZml4RS+GbbC6fDW1JbXYts2xoWM0ljaim7obGD0xdILuZPe0qlMLK5H7U/281PkSAgKl/lI21W6aVjbZbLPQ5jNbpui5FzFnyL/Iu1p3ueqBec3waDbK3o69rK0e2Tt1OhzkZF+QDXUbqPBWcCp2is5Ep5tCmNYcPRXd1N1OXjY2pmUymBl0OzgBNJQ00B5vd7JNBA+GfdZ7DythcmYO3dRdeeG8kdUt3TVq+euPB1mQnayaAsM3GvntUdXJ49YtnY54B1X+KlJayrmn6JT265aOIiusLHeyRjJGZgSFNF2IiBimQUpPjTk3T/kAmJaJaZuUKWVkdEcMzJ1ICm6XnwR1Wx9xrbxhz19LszTKvGVU+CqIZCJYluWuXvLHdyQ6CHqDSIJEQ0kDyVzS5e/jahxJlPjWrd+alqEs5L6PDh7FJ/uctE81Me0g52yDo5OJ251vw18sYipiTlCoyW3bjhHb17WPvpRTfFPqK8XGnrQ351TXzVM5//jsP3Lnz+5k03c2seaBNbQMtKBICutr1rMsvMyRx5X95Iwcfak+snrWpQwEBLBxRb1SuZRDFYmKkzctyXhEDzIyq8pWsaluE4qguOMRBMHt4ZrHZEZbFmRMy5y20dVMDc1ysl8M06FG8hOIYRmohoppmWS0DM+ffh4RkVJvKZLoGNa8pHD+3nDWgx4NRVQwcfLqJaQJx2RhUeIt4caVN475rAICEhIBOYDiUfArfpaVLmNdlVOs5JN8jnd/5o9hGY5Amam5nHvesIs4qwGf7MO0TTrjnWSNLE2VTayqWMWlSy6dleZ6YdFZXI3jk30jer5Ox8GYjrb9TDBVH9u5QNFzfwvgQgSTCj2bMn8Zg+lBomqUJ1qfYE3VGpaGlnJVw1UzzmYY7TFppsah/kMk9SQXlV/EQGoA3dTpS/e5NExADiAI43uxJqabCeOTfJR4S8gaWWRJpkwqQxREpwoSi+5UN4PZQadeQPa7qXaGbZBOOnrk+eDoaIhn/Ca/7CehJ6b9HPMTkIQEAi4dIyK67fTyVNBwZtgNzJb7nWcUy8bclERREMF2PGoTc4xRViSFhJ5w4gIFnnMhCsdh2RYZLTP+MzVylHidnrYhT4gKfwUnh0/ilZ38fEmUSGtpdEvHsAxiZsxJ+Tzzxyt5KfeVOxOYqRLyhBAEgYvKLqKpqsltQJJ/j/MVrNN5jwu577A3TFyNYwu2q0s/nSDnXAdHL0SaZNFzX+S4EB4CjPRsqgPVdCe7neCkbRPLxtjfvZ+bVt404643oz2mo4NH3VzrgCfgepU+yUd/up8/9v6RY8PHiKpRPIIHWZRdQ5uHKDgVoctLl1MXquODzR9kSWgJtaFabr74ZqpD1YS8IYKyU0Zf7i93dVMMy3Bkcc8g7x0XIh/sLPeWU1dSN+NnaWM7xtg+y2PnA5V5w25hOSmJNuSsHH3pPo4NHiOScXoOB+UgK8pWoIgKBsYI+ggco5020u79JoIkSiiSgkfw8NjRx9w0yMKxgmPgvaIXRVQYzA7Smeh0C+lkUcYv+/FKXsdzPzMZFo7HI3ncv7Igc8uqW7h3y7088ZEn3HjMbN/jwm5L5b5ybGyaq5qpCdZMu4PXaPmDc+38NdcrgfFQ9NwXOWbjIczG0y/0bCKZCA3hBoazww5X6y+juaaZQ5FDfKD5AzPyTMZrjK2Zmitx65N96KaOaqiuJK4kSPQavWi2E6ATJRHLtFxDpFs6kigxlB1iXfU6AGJqjMHMIIcjh13NleVly7Fsi5yZo1KuRBAEuhJdrmSAiIgt2Iy2jQICkiSR1JNkk9kJvfuJkDfoJiYe0YNu6fhlPxljrNdcaCjzE4BH8CCKIiVKCQFPAC3nTEaFBl4WZQRRQDO0MV59IWzbptJXSam/lLSeRsIJ6I53fEpPURmoBGAgM0BYCZPRM1iW5dYS2NhIOHntHtGDqqvotk5aS5PVs64AWUJLTNguEKbv6Y5+l//39f/bPW8m2WRznYV2IdIki8Z9kWOmhRSzbWBRuPSNqTGnACZQxbZl26gN1WLZ1qy8ksLrqobKQGaARM6hEgbSA2imxmBm0G3lltEzjqd5xijmzNy4gUbVUDFMg+pANf2pfvrT/aiG02DCMA36Un30p/qp8FfQWNpI1sjyweYPArCrdRdd8S5iuRge0eM0qS6AaZtISI4nKnrQ0KY07h7B43rFhWPNf658I4zRGP25JCSX0z4ZPUlOdzpASaKEYRmOmJcokzNy1Phr6Df6JxxTQA44/L6RYXv1dvpT/Siy4j6nQiiC4uazD2YGHakC08S0TJJWkpAnhCI55+bjCaZljgi+ioLo0DK6yvGh4xwfOu6+c7MpCJrsXZ5NdtZsO3+N5yxdiDTJonFf5Jiph3AuWQF5zwacwGPesE91z8mwoW4DtzXdxldf/CrHh47jk3wE5SDxXJzB7OAI42ZhkTNyGJYxYsk/npeZz8t+uftlQkoIwzSwLGsE7ZCX401rafweP7/v/D0ZM0NXosvhwgXByZ0vuEdex9zGptRbiiIp6Ibu6LqPM45C2mUiD38mXr+JCTZohuaqTcqC7OrOAFiWhSg4nn0kE3E110dDNVS8shcBwf3MljX+WIJKkCUlSzgVO+Xo1OPQMZrlrBrSepoSpcR9NqItjgjO5n8fsiBjCzb9qX4++vOP8jfP/A0hJcRAegABgeWly51YS2aAgfQANcGaCbsxzXf5P0w+wZzvepSicV/kmKmHcC4l03nPJn/PvJztuXglLX0t/Oi1H3E6dhrddGRmLcsaURlZCN3WESxh0pzvQp64N9WLR/JgWU6jiryxLkRej+W37b8lIAco95UT0SMYluEGOk3bdL14URBRRIUloSVopkan2TllCmReA2amFM7o6+RhYmKbjt6MbuvYllM8JiJiiRbV3mr8Hr+raa9Z2oj0R8CNVwypQ+zr3OdQRaOeuwcPiqygWRqJXGKEHIJqnvXw89o3+XMtLEbX2NjYIOCmW4LTlAPbiWPIkszx4eMcHjhMQAm4mjyf+dVnWF+znpyZG0Ejznf5P0w+wey4bsd5nWSKxn2RY6Zc4VxwgXPJT35575d5vuN5kloSSZRGBBUngmY73uJUhlISJMLesFPdKTirDY/owbZsDJzJQRIdw63ZGh7Jg2qo9KZ73SCjZmsu565ZGiIidcE6aktqHQEt2Tulsc5L6Y4Oep4rCqtF8xSI3+NnXcU6rmi4gt5kL23RNie9cpxsGc3S3M80OpAKUKqUIkuyq4SZz8fP5+Tr5sh891JfqVP9WqBdX8jh5wuZ4OyKxrAcTXxBdALo8VwczdKQLZmm8iY0S+OV3lc4NniMpeGlHB44zIGeA9y18S7aom3s79pPTbDG7bR1oXWW5nOCKRr3twBmwhXOFReYv99DBx5iV+sunmh9gqsarnKVAaeDlr4Wdp/ajW7qbtl/YWn7VJjKuIuIDvd+RnJgvEkj741rpoZgCu55STM54XVzZo6miiY0U+M3bb+ZcpyFq4zZeO2jMTrGkNeLN2yDlJbiZOwka6rXUBuqpUQpcfj8SdLw888xn4eev3ZSS+KVvZR6SzFMh4oJK2GSWtKhuUZ9Fs3Q3BxzURTxCl4swSKn5zAwJlxt5Wmj/PW8spegx2lGcmzwGKZtEs/F8Wf9ZPQMrYOtvN7/Olc3Xs1wZphYNsZLnS+5Wv/nwmvPNNlgPvVlisa9iDEvbL6Rwun4aRRJIegJ8s3ff3PamTMtfS08eOBBfnn8l2T1LHWhOgJKgOfan6Mr0cX/ueH/TMvAP976OJIgYQtni4xg8tS9QuS974mg2zq6PtYjLURhhkohpTARLCyiapR9XfuIqbERaZPzhbwHrEgKpmWi6iq7T+3GMA18so9yXzkD2YER5yii4lbg5p/j6M9t4QRuI5kINjYhKUR9aT1tsbYRRV7gTDjD6jDYDt0T8ATweXyUe8s5FTuFguI+a2HUH9M2UXC07vPB9Ly0b1JLgo2bphrwBMjoGVepU5EVuhJdmJaJIik8ctsjs6ZCZpNsMJ/6MkXj/hbHeC/sk8efHNPJqDpY7b7MhcZ/tMHPX+/Y4DFUQ0U1VN6IvkG5v5xKfyWRdGREQGv0xLK+er177WfbniWVS6FaY7Mz8l/8iQztTEvx5xKWbdGd6AYbdCafPM4HRn/uvLedb7aB7Qh+5cwcoiCSzCXHPK88PTIV8p2jbGxUSyVrZFlZupL2WPuI35uNTc7MoYgK1YFqUrkUMTVGQ0kDf3Lxn3AocoieZA+iIJLW044xFh0u37KdQLksyCiSgmZqTnD2zEpOt3R8ss9tEp7/HM91PMeKshVcUnkJWT3rTC7ngNkEaOdTyK9o3N+CGK/xwXgvLDDmZY6kI9z3/H1ct/y6cb2X/BcglouRzCXdopSklsSwDMp95RzsPciOPTs42HuQU7FTNFc3c3HlxRwfPM6PX/sxWxu2kjNy9KZ63RL10QgpIQRbIGNk3OyMQuGq+TLscCalr0CfZqEgb7AVUcEre0npKVK5FDlr/DTL6SIfLM2vWkq8Tn69qZsjVDYBtwNU2BtGszRyZo7XI06bxHJfOQktQWO4EdMy6U51OzLIZ/L2BzIDXLn0SjRLcxujhDwht+7Btp0VCjZufCYvVCYIApX+ynPKlJktfz7bFMpzRbFC9S2G0RWrA+kBDkUOuRowcPaFHa+KrjvVjW7qEzY0zp+TM3JOcwocY5evthzODnMqfsqt8BMQODx4mIH0AMeHj5PW0vz21G/ZfWq321d0NGr8NdSF6qgvredtNW+j1Os0eM5nd8xlUHI2mElcYD6gWzoD6QGwGXdVNFPk4xUewUOFrwK/7HfpkvGOjapR+tJ9+GQfV9ZfiYBAVs9SGaik3FfuFH8ZWcLeMOur17N12VY21m6kvqSeMn8Z66rXObSPANeuuJb6knpEwYmfIEBVsMrJWJIVJ9irZ1FNlU11m84pkDlZY/SFiKJxf4thdLf5mmANIiKtg63uMfkXdryXOZKOUB2oHrFNNVR2te7i7l130xZt4+TQSWfJbDlNJTJ6xqUEcmaO9dXrKfeX05fqI6bG6En08OSxJzkxdALTMklpKZKa8wXPdyryiM4KQEBAEARXfiBfMOWX/SM89vk08BNVcC4U2NiopurKD8BZmmu2sLDImlm6kl30p/qdeMYodcjC+xuWQWWgkmNDx5BFZ2XXl+qjIdzAkuASYrkYtcFaKgOVbi9gURDZ3bYbRVJ4zyXv4drl1+L3+PncFZ+jLlRHZaCSiysu5uplV7O0ZCkVvgoSuQR+j5+tDVvxyb5zMsRzLUFwvjElLSMIwiPAu4EB27bXj9r3t8D9QLVt24OCo636f4E/ATLAXbZtvzL3wy5ithi9tJys8QGM7TXqET0jzu9P9bO3Yy9hb5iGcAM5I8ee9j2k9TR+2e+0kzNzmJZJqVKKR/YQUkI8dfwpTidOIyJS4ikhpsacYB+q47HbowKY1llRLdVUWe5b7vCvlkZtsJawN0x/up+OWMc50wxvReRlASYSEJvBhUhoUwul2dj0JHsoUUpQTdVRqLRNBMHR5bdtm5gaozp41pGIqTFkUR5DISb1JD+5/Scjs1jW3sGTx58co78+WW/WqRIGFkojnOliOpz7D4EHgB8XbhQEYRlwM1C4znknsPrM3yuBh878W8QCwejUrNpQLW+rfRvdyW66El1jXtj8y3yw9yCxXIwKXwWHIocAWFWxild6nbl785LNiILI6srVtPS3uOp/5f5y6kJ1ruxtTaCGx44+RkbPINhOsVFMizmNNBDJWblxi3ny/xcRUXWVxtJGTsdP4xW9xHIxV8s9pITIqUXjPlNMFpye4YUQ7KmD2bIgk9EyJHIJNFNzKbXWwVYkQaJEKSGtO3oz+fTJtJ5mVfmqEdfJU4jj8dpNlU2TGuLZZL/MF38+G0xp3G3b3isIwopxdn0D+P+AXQXb3gv82HZKz/YLglAmCMIS27Z752KwRZw7xkvNmqzxQX5bW7SN5WXLnW5HQyc5NHCItJYmZ+bYvny728sSnGDW0tBSti7bytHBo8TVOKW+UkRBpCPR4Wh5m7pToSiAaDvaJ4XVmhN6kAI0hBuIZCJE1SjD6jBNlU0sL13OyehJ53pn2EZJlCYMyEpISKI07ayQxY65opEmet6FyOfWa6aGX3Za6RmW4XjvlomBgSIrhMQQ4NCEpm0iCRLRbJQ97XtYW7WW2lDtpH1583/z3vk3f/9NpyIXR8u/LdpGfUn9hNkv89F3dS4xK85dEIT3At22bb82alc90Fnwc9eZbeNd45OCIBwQBOFAJBKZzTCKmAUK5U+nK7s7mqdvqmqiubqZWC6GgMDBvoMcHjjMnvY97GrdRSQdcfuGXrfiOt675r1sqttEvhOSLMgOb36GOxcFkQp/hRt0zX8B88gHSWXBaaRRH64nrsZJa2kUScHv8TvNmS3TbUNnY09qaEzMs02ci6GnEZCRJ23eca4wLCe/PuQN4ZE8I9rsDWeH0QwNzdRYXbGad65+JyvKViAKIlcsvYKQN0QsG+PF0y9yYugEbdE2OhOdE0oBFyYQeEQPe9r38Fz7c3hEDwPpAV7vf53+1FnxtPxK4HxLZecMk954loHEuQe0J8KMUyEFQQgA/4BDycwatm0/DDwMTg/Vc7lWEZNjPA9kuqp4LX0t7GrdhW3blPnLWFu1FhubQ5FDpHIpyv3lHI4c5mDfQepL6qkKVKGIClE1yomhE6yqWOXynWXeMo7px8iZObcnqSzKWJZFIpeg0l/JcHZ4jLRtvjuPbTtZGSejJ10DUOotdZfulmUxnB12zxkPhfncCznoOZ+YqvjrXGFaJgFPgGXhZWimRlSNjmjPl9ST+C0/B/oO8D+3/E8Alpctd4PwrYOtdMQ6eLHzRbyylzJvGQ3hBjd7C85634WOyZ72PYS9YQCODR2jJlhDLBtzG2/D2WSCuRIds22bobTGYCrH06/3jdm/qibEbRuXzv5hToLZ5LmvAlYCr53pTdkAvCIIwhVAN7Cs4NiGM9uKmCfMhlfMTwb5PHTTMgkoAbJ6lpc6X8IjeYirjipjUnPK8G3bpjfZS4W/gltX3+p++f7Q8wfqS+r57OWf5benfksil8C2bSdoajkl6XnPbduybexu242mjaVKNEPDFpyilf5UP1X+KmoCNaT1NJ2JTtJaekKNlEKMZ9DnhGsuAjibpSQijvu7KFFKKFFKAIfqy2sFjdauyZpZLCzufvJuPKKHKn8VS8JLWFu1ljVVaxjODrtUTr6l49aGrdSF6kbknhcmEMTVuGvc42qcKxuu5KXOl8ZNJvjm7785o5x227bpjmU52pvkWF8C3bSpCikosshgSkMzRr5jNWEvV66spLrEO9NHPG3M2Ljbtv06UJP/WRCEdmDLmWyZJ4HPCoLwnziB1HiRb59fzNQDKZwM8nnomqWhqRrlvnK8kpfjQ8dRDZWgEnSaUetpV7s85HV40q5EFwFPgGsar+Fg30H++pm/RtVUpxxfwO3IIwgC1f5qwr4wu0/tJqElXJokbxzyjSuwz/TZtG2GskOOXC0Wiuj0OC3y5/MHCSdmElSCGJaj1S4huW0C85lOsiBT5ivDsAxyZo5MLuM0MB9nEZVXAZUFGcN0ePi8cyHipPECzspN8tE62DpGHKwwgaDU56zywDHUdaE61levpyfVMyaZYDJNmMFUjo6hDIIASdUgpRq0D6XHGPCw30Nt2MeVKysJemXKAx5k6cJRgNNJhdwJXAdUCYLQBfyzbds/mODwX+GkQZ7ESYX8izkaZxGzxFRVdYWUjVfy8nLPy2T0DDXBGjpiHQCu8Q4rYQzbEXhSZMWpEhWcXpw5I4dhG7QOttI62Op65P915L+QBac5RM7K4fV4SetOfnWeIulOd9Ob7nXz1CfzvvNedmGhUNGozz9MnHhHXkJYt3VEwWm8nad58vESURDZvnw7lm3x49d+7E4Ao1dV+f6woiiimip9qT5Wlq3kVOwUS0KOFw/wUudLeCUvMTXm5p7nUx4LEwguqbyEvR17AdhUt4loNoosySOSCVr6Wtzq6bboaVaXbaYhvIr+mElPdCnbGrbxk30d7hj9isS6JWHWLQ1jWTZlAYWm2hAlPs/5feDTwHSyZT4yxf4VBf+3gc+c+7De2phtlH688ybyQBRJ4VNPfYrftP2GSn8ly8LLOBw5TG+ql4vKLmIwPUhfuo+gJ0jQEyRrZNFtneaqZrJGlmg2Ss7I4ZW9KJJCSkuRM3Pohu5K7kKBCJQgOCJgto0Hj9vXM48iNfLmR6nXacWnmRqKpGCYBghOgNYNlsteJEHi6OBRNtZupLmmmdf7X8cjesiZY4XhPJLH7ayVNbJoluM0vK32bS5Pvm3ZNjclt9xfPiblMeAJ8FzHcwgIvK3mbVQEKtBMjSX+Jdyz+R6aa97mcOJHX+N7+3+HX67AK7+TUiPKoY4BIuEolb6L2dawjtpQLWG/h0tqS9jcWEbQu3AVXITRgvnzgS1bttgHDhyY72EsCBTSIoXFF1NltEx03m1Nt40p5ngj+obbps62bQRBoCPeQZW/iqgaBcHxspK5JKqpUuIpwevxUu51mgtvW7aN07HTHOg94HTPEWUG04NOgFSQx9X+FhHd5fc5F8oUsSCRz4LK68nkWw3KouxM/JaOhOQ4BKLC1cuv5s83/jl/+8zf0p/ud9ryFfRzlXCac5f6Sl1q50PNH3LoHD0z5Xdk9Hcilo3TG9e4ufEuNK2SurCPjGYQ9Mp0DGXY074H1VBdxcmashSmGGFJqZ8v3/hPnIkxjrj+fKdKCoLwR9u2t4y3r5gDtsAwOu1wtHbLTM87FDnEbU238Vr/a+w8tJPX+l/DL/u5qPwiJ8/Y48e0TWLZGMeHjzOUGWIwPUhcjRP0BJ2AlWDjl/yU+kpZWbaST235FJXBSm666CbWVa9z2tqJAl7RSWEcr4w9n55YNOyLF6Ztuh46OJO4ZVuohuqmnZqYqIZKUk/Sk+ihqbKJf7v532gsbSTkDeGVnACjgEBQCbpZUpqpUR2oJqpG+fSWT0+ZzjuYyvHIgV9hayvQ1WWc7Kqho7uZRGwtTx15Dc2wOD2cIZbr5dnO/2Bf5EHac/9O49KjbF7dw+bVPdRXJ2io8NCbbh/XsJ/PVMm5wMJdU7xFcbD3IFE1SiKXoNRXytqqtVQHq6cUPJqIW3e4wzY21m5k+/LtxNU4vzzxSyr8FZT6ShnKDNGT7HF7gnokD4ZpOJkntkmFv4J3XvxOakO1Lr2T72v6wMsP0JPqwbZtfKIP3XZ6bE6UYrjQBbWKODfY2GMabowXD1EkhYAnQEeig4cOPMRD734IgPv23odu6fhlP32pPnJG8Uf0JQAAIABJREFUjqAnSMbIuF2hVF3lwQMPopkajaWNfOayv2Jl+Vp6Yll2H+nn9e6zWkgH2yXC3nqEYA5RtKkqTZNWZYa0A0SEPo5EXnFVSdcsuZiOdI4XOvdwnXQdAEcHj07Yp3Uh9GedCkXjvoDQ0tfCqdgpBAQ3sv9S50usr1nP6srVk547Ebcey8XcHGHA1VU/2HeQS5dcyuNHH0c1VIcjPbOc9nv8TgDUyFGilGDZFscHj3M4ctjx3J/6FJ2JTjbWbuSSykvYeWgnqqkuSJnbIs4fJEFyguWz0PIJKSHSWpr9Xftp6WvhgZcfQLd0aoI1bi3Fi6dfpCfZg2VbNIZXcHHpRl5t17F1L8vLmujukXn29V9ze3MGzEo8kkB/qp+jg0dJG4PkpBb8YYWVNReRd7yPDx5nIHOYtO4foUoa9oXZvGQzz7U/xwunX3CL62RRZmlo6Zj04YXQn3UqFI37AsLjrY/TXN3M4cHDLveXM3Icihzi9jW3j1tiDc6k0JfqY3fbbir9lWyq24RP9rmFQ6NlezfVbeK3p37rNEwWRLdoSEJytFtMpw1anb+OgCfAr078Cr/Hz+VLL2dVxSr+++R/O2p7sp/jQ8fdpgmTGXYZ+bwXxxRxYWHZ/z97bx4k13Wdef7u23OvfUEBBRD7JhCkaAkUJRAtSiPLtiQPTDva0xPRbk1E90jjVmj+mYm2Wj2MYNvR41FHKBS21dHTdig8nvZYlmlLctukJVIkJRESCZMABFAgtsJShdor98y33/njVj5UFaqAAoiVyI9/gFX58uWrzJfnnnvOd74vxtAN/Nhf9NlfzyjFizzljWrYNIMmXzn0FabqU/Skemj4TX507uf0O4/SqDxM7PZg6xblubX8dFrgGAXC2OOdmZN0p3tY29PgrblvMlTo4u2Jf+R8ZYTdvbt5uGsTZ+d0Do3+CF0P2dy9mTOzZ3hx5EUyZoajk0eZrE3Sn+3HDV1OzpzkwIYD7F+/n2+/8226Ul30pa94rxabxUVZeSuZ8iM/kdiwdItHBx+97e/7atEO7vcQLpYvsrl7M3knz8mZk0qTJVVAk1rSFF06iARX3JKeeugpjkwc4cWRF/n4xo8nol9LM3rHcPj4xo8zXh1nrjmnjIqF4inXwzppI02H08FDXQ9xYMMB/v703wMkuwc/8snZOd64/IbK7Oc5zNdCRLToS389f9M27g+kzTSdqU6qXpWyr0oirb7LSgFeItV0s7OWlFiDCIbJAcViGi3uIo5D3imVCSIbjW4s3SfW3qEUTaDHEflURCx8nMJ6TlXncIsuB3ccpOQXEVJwfOo4eTuf3K9j1TEaQYOR8ghZK8tQbohm0KToFTF1k65UVyJt7RgOA9kBPr3t02jiSktyaVZ+cPtBvvTSlzgzd4aclcPUTSpehUuVS1eVcO4W2sH9HkIrGxjIDiRCXMVmkaOTR1es78Fit6TB3OCi2jhcLdvbYhZ84fkv0J/pZ7I+SRiHyfBQI2zQrXWzo2cHk7VJLpQv4IUeKTPFjp4dFJwCDb9B1asipSRjZvBC75pqgEu1YtqB/f5HyzrPMRy1C1zwuS66D6SBRhZDdmNHe9BIkYodep11aIFGsdzPQNrkVHMEgyq2CSX3NazUHLYpiYTA1Eyi4DKBjCno/TiaQ8pMUS1V0XWdzlQnFVf1qdzQTSQFNnVtwjZshgvDrO9Yz9HJozSDJikzRd7Kc650jrHKGHk7z+nZ0+iazr61+yi75WuaWu8Z2MNQfoip+pSSwXAKPDr4KLZu3zN193Zwv4ewkpnucqWVhZnEtWp/19KgHquOKf1su0AzbOJFHiJWGXhr+u+1S6+BJJEfeHHkRcIoZLQySiCDG/alvGXSsm3cdbTorVW/StpM0+V0U2roWPFWTKnuyVjU0WSGUExgSJWw6OggYHvvMOea3+a0e4G+bAe7h3uZbpxXFF33IoO5DTiGw2h1FJi/d+b9VAfyAzSDpmLR2ErzvdWncgwnycRbQblVI9/es51Do4doBA2liCp0TMNECJXxf3n/l9navXVVptZ+5POJzZ9YlOHHMr5n6u7t4H4PYaVAvFxpZWEmca3HWuddLpMYyg1xbPIYOStH2koDKG576NIIGrw9/TYCQd5RehyNoMFkbTJh0twM2g3X+x9CaqTEECYbsEIQpBFSQ3P7yMcxsYyQgABiqvjaGUIxiRSvo+GyvW87AD8t/RBbt5mojzLnjjNeu8xjg48xXBhmV+8ujk8dR9d0hrJDTNQnEiOPDYUNRDIiZaYYyg+RNtW92wrcXuhRcAqLplVb36GB7ACPr32c5888TyhDpYW0+ReTuvrx6eM8vevpVZlyXEui4F5AO7jfIax24GGlQHytTGI1WcZy+NSWT/GTSz+h5tYQmsrYhRBJ6WWsOsaa3Br29ewD4Pkzz+NFXnvc/wGCkA66LAAmplyDGa9HQ43Wp4wUMoRY1nDlJVwxRazVkQS44gKIxQ10A+WipGkafuAzWZtUDcvMAKPVUYpukZpf42u/+DW2dm/ld176HSUfTcTa/Fo2dm6kw+lgY+fGqwbyis0ifZk+dvXs4sT0iaRUuTAot74nfZk+0maavJ3nQ+s+lJRAl+54r1daWWmnvZrv3p1Ae0L1DuBmp06XnmOhI1KH3cHewb2Jf+ONTsq1runYxDGOTx8nlnEixuSYDr//sd/n+PTxJDOZqE3wrRPfYtadve61Xo8t0cY9CKmh04kuu0lFVw88hmICXXYSixq67EbXqwhjnMi4RDMqoQudZtjE1MwronBL7gOBoCvVRXeqm0uVS2SMDOs71jNaHVVmLbHS4P/klk8mZIGl9/Vqf7eSKF7ruHPFc6zJrmFrz9bk8da9vlo57KXnvBtTqteaUG0H9zuAZ15+5qrt283eSO92kVh6TUcnjzJTn6EW1Kj7dTJWhg+t/RBbe7YmmUkYhRweP8z54vllpQWWoh3c72FIDVOuxYw3LKiL14ipJTXxhQjERXztNJEoIfESk5X+VD8lv4QXecsOpy20SmwxqSSSwewgQ7mhZFI6baXV8Jxm0vAbNMIGw4Vh+jJ9K7qD3Qrcyu/Szb7+rVgUrhXc22WZO4BbNfBwM1NxK91ErWsqu2W60930iB6klFS8Cpu7N3Nk/AgAFbfC65dfp+JVVpRmXYp2YL8HIAWG7EOX3ajqt8CUa9FlB0tVRyIxSyDG8XiHWJSIqbMSs1WiDFPGG9dW8m4pfKaMFKZu4kc+fujjhi5pK82mzk2M18YpuSXFbw8alL0yBbtAT6qHqfrUdX0H3g3uptn1zXgs3Azawf0O4FY1XlazSCyV8L1UucSmzk1X3USta2oxDFJmirnmHFW/yp8d/TPqQZ20maY/20/JLSnP0+vwl9u4OxDSRpM5NHIYshcr3nzVMZGYJRIzhGIcgUkoZgjE6FV18VsBXehEMiImxo98IhkRRAEZK0POzlF2y6SttDIzb3o0wyZu6JIyUgx3DONFHn2ZPsIo5AvPf4GNnRtvS8njbpld3ynpgnZwvwO4VY2X6y0SSzOC1iTpUguyPzr8RwgE3zv3PYQUXK5dxg3dxPjC1E1szea/nf5vGJoySliqGdLGXYA00ClgxVux4oeWPBgTipn55qdCJGbxtRF8ce62BPGVsJBJFcoQXepqEjpoKGMWO48buhiawYbCBtWgd2Fdfh260HEjl7yV58WRF/EiD4nEDdx3nd2utIu903XzOyVd0FaFvAO4GVPq5XBw+0GKbpFis0gs44TqtbCptFAZsjVJenLmZHION3T5/rnvY+kWj/Q/wkR9gkbYSLjnfuxTD+rUgho1v6ay9lXU2du4hZA6ZryedLifQvA/kA73kws/TSbaTzb8xFWBvam9SV3/AXX9FSrGX1E2/ytl879SM17A107d0cC+FLrQEzGwlJ6i6lc5XzrPueI5qn6VXX27eO43nmNX3y7cyCVlptjatZWfTf+MOI4p2AXcwOXEzAnCKLyuOupKWEnF8VsnvnXH1R2HC8MJD7+F20GhbGfudwi3agu40Hhg39p91xQz0oXOWGUMN1QO69t7tnNk4gjdqW46U50cnTwKgKM7BHGAhpaIf/mxn5Rg2qWY24T5urhAlVVUXXx4vi5+BYbsI9TGCcQYHqeIRYWYKoh7/zPpy/QRxzG1oMa6/DrOl88rO755E5i3Jt4C4Gu/+LVk13lk8gh+6GPqJr2ZXlJmCoCx2hiO6dzUdaxUCvmDN/6Ah/sfvqPqjneKQtkO7vcIrrU1PDZxjGdffZbvj3wfQxgMF4bZ1r0tsatrPfet8bc4MXWCRwYfAaDiV6i4FRBwYuqEGgoROr+6/VcBlS2EcYipqYaXFIsD+dJ/23h3EDKFKYcx47UYsv+qxwPtAjF1Im0OIW0C7cJtq4vfKTSCBgW7QNkrM+fOkbWyZKxMovHu6A5feP4LdNgdjFZHqXpVphvT2IZNT7oHgPOl8zSDJrGM2dmzE7hxtslKpZCx6hj71++/6ve3c8r0TjVz21TIa+BW1eKWnmd3726OTx9f9PNSt6QWLQvgd176HX508UcEUUAs502l0708se4J8k4+caVxQzfxiEybaapelYn6BI7hEEZhosa3tXsrHx7+MD+f+Tn/ePkfCeOQMFYBJJJRO5i/G8zXxXXZgSbVv552klC7jB73ko0+DsS0KqKRmMXVThCKifs6iC/EQhqkYzjkzJwSCwtqWLpFxswgpaQRqHJgzszRne5GE+o5Ukpqfo1YxtSDOrZuK9NtGbFv7T5+6+HfWvH7stL3cyU68tHJo4sy99bvb5SmfLfQ5rnfBG4VD3bpec7OneXQ6CH2De1jc/dmym6Zl8+/fJVm+8Ib8a/e/itOzZ5KJHpbwbgr1YUXeWzp2sKjg4/Sn+1nsjbJm+NvcnruNHkrT87OYRuKNWMIg7pXxzAMetO97O7dzWujrzFdn1ZfLBm36+urhdTQyKHLjvlsewYhM+TDz1w5hJBYlFXw1kZBaggsJO6KVMP7Ha2grqHh6A4I0DSNx4ce563xt6gGVQzNIG8rSYsgDAhkwLbubaTMFM2gSRRH1IM6s41ZDM1Q9nyazkeGP8Ka3JqbCsg3YkN5J/nu7xZtnvtN4FbRlZaeZ6w6Rt7Kc7l2ma09W+lMdRLEAaOV0UXBfeHWcLoxjampke/WEEkYh5TcEgWngJSS1y69xrbubUw1pvBCT5lvyJCKV2G2NItAkDJSFFIFHMNBFzo/vPRDOpwObN1msjZ5U6YL73lIABNEABJS8ePoshNd5mll3752hiYzSOq42lEiUZ7ni9cWB3ERq8B+H+N6/ReJREPDEAa+9OlN9fKbu36T6eY0+WIeIZQJRhRH+JGPqZnIWCa+pY7hUPEq7F+/n798+y9Zk11Dh9OR6KrHMr6pUsq1SiFbu7feFb777UY7uK+AW0VXWnqeslsmb+cXdct7M71M16cXPW9h9zyKlUhSI2hADF7oKQ5x7CcUMyEEr1x4hQ0dG7AMC1OYXK5eTnTaDc2g4lfIO3lyVg4/9ulKdfH0zqcpu2X+/szfc7lyWZVuHmDaox73otOFLq+UViIxTd14WWWhMk1MnVAbIxIlFcipqCcL8PQTd/X6bycszVpRV0hDw9RM0mYaL/LY3bc7MY35/vnvs6tnF+sK65htzFL1q9T9OhJJZ6oTL/IUz91M4YYuBUclIHv69yzK0CdqEyr796q8cOaFZLcKq2ObrERquFt899uNNhVyBdwqutLS8xScQuKP2sJQdghTN5elOB7cfpDOVCdhHJI206okI5X2eofdQXeqm7HqGBO1CaJY8YtLbolG2CBlKJZBy2BYSsloZZTL1ct4oUfaTPPqhVd54cwLjBRHaISNxJneEIvXfeO9lAdIA112Y8WbcKJHSUUfSB5y4j2kovdjxuuQhPjaOXxtJHm8brxIw3gFVz+qGqCiBOK9L2Hc0oyxNXtFA3THdBImjB/5vDP7Dl7kEUQBY7UxtvdsR9M0+jP97OjZQZfTRRAH7OzZSTNoUmqWaIZN1mTXUHSL/PYv/HZC/R2vjvPK+VeoeBU+vO7DVLwKL59/mfHq+FWU4DYU2sF9BVyPU36z5xnKDVHxK6zJrlnkTdrldHF08ijHJo4t4sHvGdjD73309+hNK81qXdNxNIesleWhzoeUW7yA2eYsJa/ExfJFDGGgCY2uVBcpI4VlWMTEyoFeqjLPqblTHJ86zrm5cxTdYtJIbQZNgji4StL3vrTIkxqaLGDGw4lsghO9n0L4G2TDT5CKPogVb0aTheTxpv4GFeM5KsZfUTdewtX/kUC7cPf+hnsEQRyoWrqmYekWGwobSBmppHm6qWMTQ7kh6kEdL/LQhEYzaHJo9BApPcV0fTqR202ZKWaaMwx3DPP7H/t9hjuG8SOfifoEfuiTd/J8euunOT59nIpb4ejkUX5w/gfk7TwHNhxgd/9untzwJHk7z+tjr+NFykj7qz/9Ks+8/Mxt5ajfT2g3VLn9k2srsWWOjB/h7Zm3sXUbXejYhk1fpo/f/ejvXvU6rXP88Vt/TBiFNIIGlm7hR0qvI4xDCnZByamGPpZhUfNqakJQ6ID6gkqkMheQV/Q/DGHc36WY1i0swIj7seTmeabKlbp4xXgOKVyMeC26LKxcF29jWbRq7brQ6U33sq1nG1JKjk4cJWNl6Mv0UXSLlJtllUQI6En3kDWzSZ39wIYDy7LBljY6zxXPIZEU7AKjlVGmG9NMVCf46EMfZXf/7uSaYhlzbOIYeSd/3zZE3y3abJlr4Haqw11vcfjc336Ol8+/TN7O4xgObuhS8Soc2HCAzz32uWWlTZ/+y6epuBUCGVD1qglXOGtlE0eYql9NaJOmrrbTUqpAbmqmkmeNmu/qb7trkAaG7EajY1FdvG68SCTmMOOHcOL3EaGC95W6ePm+GPq5F6GhoWs6Uaz0YjrsDgp2AUu3mG5O8xs7f4PB3CB//rM/Z6Yxo3pDkLC5dHSe3PAkp+dOI5HsW7uPzz/2efYM7EkoiguNpqcaU6T1NGkrjWM4OIbDyZmTRDLi13f+elJnfy9QGd8t2myZa+B2ifisRvntJ6M/IWflkgm8lJlCSslLIy9RD+pXPbcZNAmiIMnUW1KrsYxZ37EegOn6NCVX6WunzBRCiqQWL5HYuo0buff+1OkSvnggLhJpMxiym0z0lDoEj0iU8LVzSBSFMxAjBMbItc7cxnUgEBjCSGixmtBUNo6yyMtZOSpeBYnkscHHEqaLF3kYmkHOziWCYXEcIzXJYG6Q7b3bk+SphSPjR7hUucRIaYSUkWIgO4AXeMw15tjUuSn5bqzNr+Vs8Sxvjr/JJzZ/YtUWlA8yHvjgfrtEfFazaNSDOnW/TiQjHMOhJ9WDpmmUvfKyz/2Hs/9AT6qHilchkpGilMkoGUDKWll0odMIlCb2bHM20Wj3Io+KV1GlGSkXaWzfVczzxSEiFjWETJGNPo4ms1cOISTSS0TMEIpZ6vpL8/riy/DF2yWWdw1NaLR29BoaKSNFM2wSyhDLsOhOd5Ozc0zXpzk0dojXxl6j0+6kGTUJoxBTN9nUuQlDMzhfPE/Gyqxo7j5SGmGiNpE0/0cro2iaKhvW/Bo9GTWlamgGmzo34UUeo5XRVVtQPsh44IP7u5HjvVbZ5XqLRqvp0wgUqyWIAs6Xz5MzcxScwrLZSBAFzDXn1NSfncMLPWabswRxwM8mfoZt2sQyRken1CypLF1z6U530/Ab1PyaanbN16HvSvYuwY53oVNAkx1JXdzXTtHUDyNxicQMvji7fF1chGqas43bBoEADYzYQGhXDM1NYZI20mzp2qIURVHzFo7uMNOYwdRVya8/008sY1JmiqydXfF78NzJ59jVu4tL5UsYmqEUSOcnUR3ToeJXkFLihi5u5LKrZxdbe7ZeVW65l63u7ibaNfebrLlf73krjTt7kcdAdoC/Ofk3RHFE2SsTxZFiq0hJwSnw1ENPYenWVc/98aUfc3r2NJZuqfJM5CbBuiXwJRDKsmy+IZWzcsw15wjigI2dG+nP9HNs8hjTzenbFtw1mceKNyCJ0MhgxZsJxCgNQ0kj5MLPAHJBXbxMJGaJRfWWX0sbN46F90XWzGLpFpGM0NERmgroXqgcmHRNpy/TRzNoogmNDqeDvJ3nE5s/wdm5s3x/5PtkjAzDHcP0pfuYakwxVZ+iL9NHh93BnoE9/N2pv2O8Nq6Cuu5gGzabOzdzePww3eluejO9DGWHMHRj2e/l3ba6u5to19yvgZsV8ble2WU55beWma+t24AyGPYij7ydJ4oj8rbq+n/usc8lz3VDlyMTR5htzvLIwCOcL51XtMr5bKpljGDrNp1OJ9ONaSIZkTNz1IM6Vb+aLBofHv4w/dl+Prz+w/yXf/wvTNYnCWV480F+vi5uxsPY8Y55n80OBFeU+yQeIJHiymRmVf/uA8ENv1+x8F4I41BJ9uopmlETS7dohurfRthAxAI/8rF1m3pQZ//6/fx07KccmzjGSGmER/sfZaw2xnh1nCPjR+jP9mMbNmuyazgxc4K0meaxoceSPlPNrxHIAE3T+MNf+sNFGkw3air/oOOBD+5wczfH9couyy0a66J1SUbe4XTQDJp0Op2kzBQHNhxIWAPPnXyOilvh7em3maxPsia7hqceeoqaX6MRNNA1HUtT2XskI9UA0wyaYRMkRESU/bKirqGy+GKjyDfe+ga6rmNoBjJWmX5KT+HFitGwIh1S6phyCBDosgM73rXsYQKTQBtDkykiUcTXzs1L0y49sB3Y7xf4ka+kBISf0Bsn6hOq7KKnkCgBMFu3ydk5HMNJVEfXd6xPzNWfP/M8mqbhRR7/5KF/wkB2ACEEx6eOs6t3F1JKoigiljFdThcSydburTy96+kbut4HOYtfinZwv0mspla/dNH47Lc/S29GDSNt79nOodFD2LpNqVmi2Cwm/F5Lt9gzsIfx2jhZM8ujg48C8ONLP04GkXT0RZ6mbqgYMBFXmDFA8nNMrBqvMUkZB0DEAiGFCsASBBmseAN2vBOQxKKxRF/8SmAOxQSedopYlOfr4ne/xNfG8rjZ3ZkmNKSQxDLG1m0KToFHBh/h++e+j4ZGM2zSDJoIBO8ffH9S7/7qT7+aJD8D2QE6nU6G88NU/SoDWWXEvalrE3W/zuXaZUzdZHvvdnb07KA/20+xWbxhxtqd8ia9X9AO7jeJmxHcX7ggtKb13hp/CyEEnalOhqKhZCKv7JYZr43T7XTzxuU3qLgVJqpKYkAi0WMdx3Co+qpOLZFXTZWuBF3oxHEaXfaiY2LIAma8EUhifIKYaUJtDE124GkniMRcO/O+D9ES9ALFPFloxnLN50mJrqkmqR/5nC2e5QNDH+BjGz/GG5ffwG/4WJrF3v69fGDtB5JMeWnyU3AKlJolOlJXEoWyW2bv4F4uli+yf/3+ZE6jdfydMJB/L+O6wV0I8SfArwBTUsrd87/7v4BPAT5wFvgXUsrS/GP/BvifgAj4gpTyhdt07XcVN1OrX7og2LrNtp5tSWbxq3/+q5wrnSNlpMjbeaYaU0w2JgkqAaZhXsm2EYQyJPJVkysiSjjvV2G+Lu5ED6PCtsBhiFhKJDESVRcXQCim50spdSJRRor7dNCpjWWhCbVjc3RHzUnMS/PGXHuxNjSDnnQPXuTh1/yEa74mt2YRiaBVEvnqT796xZydTRScAmuya7hYvsiuvl3EMl6UDN0qOuOd8ia9X7CazP0bwB8Af7rgd98D/o2UMhRC/J/AvwH+dyHETuCfAruANcD3hRBbpVxlSnmfYaVafesmPzJ+hJJXosPuYO/gXg5uP3jNBaHklRSveH5wYzA7yNm5szTCBn12HzVRQ0NTmu7zdniggr0pHOIoiyCNIfux4s3zjy3OxKVWRBjTRIGDJ87ia6cBD127Rs29jfcMDM1QMtMyoBk2F5X2loNEYmu2YmVpGgfWH+BM8UzCNf/I8Ed47uRz/Lsf/DtGyiPs7t3Npq5NlN0yApHw0rf2bOX9g+/nu6e/y+uXX2coN8Rv/8JvJ/f+l176ElOjSq46keF45Hdv6G97N7Tm9yKuG9yllK8KITYs+d0/LPjxJ0Cr6/EZ4P+TUnrAiBDiDPAB4NAtudr7AMcmjvGll77E+dJ5RiujWLpFwSmQNtNJ/W8pT7e1GJwrnsMN3IQx0PAbinMsYK45l3DYY+mQinZgxOuQ2hRSZnFQwx7BkgDdnNcXl6JBRBGERJc6kXFlvW3JArfx3kYsYzSpMVGfIIjUxOlKpbwWrRagFtS4WL7IUG6It2fepi/Txxc/+EXgii5M0SsipGqQ5u08/dl+NrIxkQFo1cMf7n+Y/ev3U3bLfOfUd9javRVYwNCZb77fzP14p7xJ7xfcipr7Z4G/mP//IVSwb2F0/ncPDL5++OucmTtDxauQNtOACsyn5k7xxLonksm8VvZu6RZjlTE2dm7koc6HuFC8wGh1FMdwKJhDCJHGc5tkeBiDNM2oBlKfr09KYrmGkAk8JglFEU8/pfTFr1EXbzVZk5/fmxur9yxaSoygGuXXCoQL6+oxMcgrCo/LHds63hAGQijpiljGNPwGk7VJhvJDDOWG+Mqhr5AxM0mNu+IqGWs3dHnj8htkrSylZgkhBAe3H7xmPRwgb+Wp+TX8yCdlpshb+Ruuld8pb9L7Be8quAshvgSEwP97E8/9l8C/BBgevre2Te+GTtXSiym6RWzdRgiR6KgXnAJHxo9wrngu6ei/cOYFym6dDmMbHfIpTjdfpTN+GCsYwo5tSm6RtJTEgDAg1EaIRAmBIJ92qQbTRHGEG1+tF6OhqeYpMYZQE4D1sH7L3qeWNV8bdxYSedUCvRKWykxEKOqsrdlXOW9pQsPQDLzIw9TNZGK0GSo2jBd7PDH8RMJmefXCq3xq26cAlSk3gyZhHDJSGmEn5ArTAAAgAElEQVRL1xYsw0Ig+Mqhr1BxK1d9h1r18LnG3KJeUzNocnz6eCJAdiNoc96v4KaDuxDit1CN1qfklTHXMWDdgsPWzv/uKkgp/zPwn0FNqN7sddxqfOvEt3j2h88SRAG96V680LshOpVUfEIcwyGIAkzdRAhBEAU8f/p7XCzNMJTeRq+5C1vrpDzzYTShceyCyYaOAVJsI9SLuL5LICtE1s/IOA0q/jRS14nmueyOmeIjG57ilYuvUHWriXJfGF+pxbckfYUUhIT4oXLRuRW6MhoafSk1cXi9hlwbtx4L6awrfY6taWUAYtB1XUlShO4iR6XWLqDD7qAe1NXOQGgIITB1Ey/0EEKQtbKJImPBKSCRlN0ynanOhNo7UZ1Q3qkoIbHH1z6Ordu8PfU247Vx/Min4BTY3rMdW7cZLgxzrnhuUa8pZabwQo+SV7ot792Dgpsy6xBC/CLwvwGfllIuXF6/A/xTIYQthHgI2AK8/u4v887g2MQxnn31WYQU9KZ7cUOX41PHieIo2T5eD/vW7qPiVsloQ8TNnfi13fj1nRj1X2Zu+gNk/E/SrO9gZG6S6fo0btRgNnyNqegFCh3vYOVeZoZvM6f/P1SNbyOsMTxZIW2n1RfMzJI205iaycmZk2zt3EokI7WNXjAtpKO+1LqmgyDxYIUrQf/dICZmojHRDux3CTHxdXslEqkEwCREQt0jaSudKDwuOg5JI2wQyxhLU3IDUawkMYQQxDK+yi5y39p9iRFNX6aPXT278GOfnK2UTh9f+zgD2QHc0GWyPknFq2BqJo2gwSvnX+Fs8SwHtx+kw+4gljHNoImUyjAmlkpauI2bx2qokH8OHAB6hBCjwP+BYsfYwPeEEAA/kVL+z1LKE0KIbwJvo8o1/8v9xJR57uRzBLHK2IUQSSYxWhnFNuxln1N1A0qNgOmaxyvvTDMo/kfyUR91zyUtXPzIJ4jm6MhI1mU2UNdeJ2ASN57lbGOC3s5eavUJwljyN6f+b+ph/cqXLWhQD+pYukXeyqup1DigK91F3srTCBvous5ntn2GQ6OHGKuOLaqbSqSS+52nzKy2NtvG/YFYxtf93GIZK7MMqeFGLrk4l+zwWvdKjDpPHMcMZAcIooBG0EikBzShYeom27q3JTTGs8WzrMuvo+JWuFi+mDDC8k5eSWEsYKwcmTjCmtwaHh18NNFsz9t51uXXsWdgD3sH95KxMoxVxyi7ZQpOgc1dmxcZxrdx41gNW+Y3l/n1H1/j+N8FbozDdI/gYvkivZle3MBNArtjOEw3ptm//qMcGy3R8CPcIOJno2XC+OovVcHu43Mf/GV+cvlHzDTH2TbQw9vTE+wZ2I4mykzWOnjt0tvMNaeJZUzGypD209T9Oo1IsWN0cYWWqKHkVyMZJWWVilthqj6FlJK55hyfevxTvHLxFfJWnjAOcUM3qa1GMqIv1adMiD33quttoR3c7y+0ZCV0dKSQSYYNavCoFbA1oSXB2dRNhCYQQqjSiVDHthQZbcPmP/53/5FvHP0GF0oXlE5RHNGZ6uRfPfqvqAbVhAQgEMkkdYuV0jKU+cqhrzDTmLniolSb4KkNT9Gf7U/KOi0XpWdefoYj40cYKY2wq3dXwqRpe6K+e7QnVBdguDBM0/c4PjVC4HYSuTvUWL/eJCh/lBd/PgWAqQtsUyP0Irx4hunoFabdczzUOcSv7TjInoEP8i/4YHLeZ15+htOzp5PMpCXdKzTBZH2SrJllMDvIsaljKoALFdRjGWPpFi17szAOyVv5K4qO81/MPzz8h4RRiGM4lL0yKUuZfkgpcSOX3kwvtmHzs8mfKQXKZZpxXU4XVb96VZOtjXsPGhqdTidu6KJpGvVANcl1oasGt1CG5oZmYOkWoBgyBbtAR6oDUzOp+TWEEKStdJIUHNhwgKd3Pc3W7q3XJBQ88/Izi7LzhcyXZw48w6e3fppnX302MfSQUvKD8z9ACMHOvp0AnJ07y0hphPUd69kzsIeMlUmaqHsH9z7QLJdbhQc2uEspGS02OT1VJWubzNY83OJTjE2kKMS7qfpV6kEdXej8+u6P8yvbdyKBdV1p1hQchBDz3N3/RKfTyYbOQUru8loWu3t386dH/5S8lUcTGuO1cSSSocwQPZkeTs+eTsyGYxSXPfE9jQJ0oVP2lBBYxa8kGVksY3zXpx7UiWVMzsrRlerC1E1mGjNIqaYRpxpTxHG8bGDX0bFNm2bUbDNf7hNoaJTcEpahjKr9yKfYLNIMmliGpXjnblHt4OIIKZRvbtbKEkbKcCMnlFtS3VOGMbt6d/G5xz4HXJ9xcr1J0OPTSgzsxMwJHN2h2+nmXOkcL51/ic5UJ47hJMe0FoYt3VvoSfc8MPZ4dwIPRHBv+CGzNZ+joyXOTNUYyDvM1n388Eowy6dM+rP9PLXxCWbjHzPnFnmoe4Bf3/nfr3ijr1bL4vj0cbZ3b+ftmbeZrE1i6ib9mX5qQY0eekhZKcaqY5jCxMVFxhIp5vXZhWI8xDImZaQStccWN12ghL9iGVP2ykpUTOhJKWdTxyYaQYOxxtiyzc+ICC/wVk2ta+PuQ2giEY5zQ9XXkUhs0+bR/kcZyA8wMjfC4cuHleKn0OlP96smqYz4hTW/QM7OcXLmJGW3jKVb7OjdsepM+XqToBfLFxmrjeHojipvmrCxYyMXKxd5fex1PrP9MzxUeIjN3ZsXnfdBlgq4HXhPBfeGHzIyU0dKmKl5vHVxeSqVoWvsXJOn0gxY25li52CBlDVPGWMr8OFVvd5qtSyOjB9htDJKf6ZfbaVR0qe6pisWgVshlCE9qR66Ul2MVkeJUcHcEAZu5JJ3FP93OS2QVimlldmHMiRv57F0S+luBw0s3cIN3WXr6u3Afu9iYS+kNbzU2oGltBSXq5fpcDpIm2k1QDTxBv9287/l6MRRBvODNAOl2liP6uzI7eBS9RInpk7QkepIFBhjGTNaGV329RfOfLRq7ePVcd6eeRtbt9E1Ra/szfTye4/8HqCC/09Gf0Jvujc5j6Eb7OzdyaauTTxz4JllzWweZKmA24H7OrgHUcyf/eQCYSTRNUG5eYXiZepXaIHvGyqwpT9Ld9YmY+lJ4+lGsJxeTMkr4YXeoq7+cjdoySuhCcXjdQyHIA4Ig5CaX2Nj50aCOKDu15lrztGR6uDhgYcBiOKI0coouqazLr+O49PHrwrOrZ9NFNWx5ana4XQQRAEXKhcIomDFqcQW2g3VewsLGU8tmJqZND/rQZ16WMfWbUxdffa60DGEwXdPf5cDGw4sCpynZk5xYuYEBVvx05tBk9cuvcaH1n2IildhrDrGZ7/92UU19oUSuqZm8sr5VwDY1btL9Y0ac3SnurFT9iIa7sHtB/nrn/91wnxxQxc3dNnctTn5brSlAm4/7uvgXm4qGiLA1v4cm/uyNIOID2zooiNt3lQQXw6tmzyKIzVwITTmmnMMZYc4NKpkc1piScvdoB12B3PNOZpBk26nmwuVC8p0Q+iM18bV8zs2UfWrTDem2da9LTnfyxdeJooi/MhPJk6XE/gyDEMNTWlKPXKkNELWyvL+gfdzZPIIzeDaCo/twH5vYeHnsTBj14RGxsoQxRH1sE4UR5SaJfxYlWY2FDYwVh1j//r9i843VhsjiAIeX/s4h0YPKTs73eZHF39EPaizb2jfVRroC8uOL59/mbydB+Dw+GH6M/30ZfoWGc20ypF7Bvbw5f1f5tkfPst0Y5redC+buzaja3rCgGlLBdx+3NfBvSdr879+fOttf53WTX508igpM0XKTKntbtRk39A+xqpj2Ia94g26d3AvaTPN5dplylGZDYUNnCmeIYxDbN1mMDtI1s6StbPU/To/OP8Dnj/zPKZu8r7e9+FFHm/PvE3KSFH368vKDHihh6mZdDqdVP0qGTPDxs6NnCmeIWWkmGX2tr9Pbdxa6ELH0i380FcNdGJFa9TMxOYukhFe5GFoBrqm4wbKEP3M7Bl1v81nzxdLKoC2fAQOjx1mtDpK2SuzuXMzeUc1+xf2jRaWHVvcdICqV2V9YX3ye7i6HLka1k1bKuD24r4O7ncKrZt84Q3uGA5lt8z+9ftxTIc/+cyfrPj81hb04f6Hky1oIAOqXpV1+XUIIaj5Snmv1CyhaRqbOzeTttKMVkfpSfeQNbO4kav8K1H0tlYjDUi+mJqmWDRpM41jOIpFEbZ12e9LSMXqMnWTtJWGGNzIVT0Uw6JP66PiV8hYGTJmhqyVJZIRXakufjL2E/JWnrydp9QsUXJL7OjZkZw6kAEDmQGklKTMFIdGDyUTpa1AvbBx2tKOAcjZOdxQzUwUnAKwfDmyHbzvLtrBfRVo3eStGzxlpnBDNwnUKzWBFjaj0mYaP/ITHewvf+TLPPvqs0zUJqh4FWbqM8ngETFcrl5mY9dG8naeYrMIArpSXcpkIY5JmSn8yKfqV4njOAnqQRjg6A6WbnFm7gw1v3ZLJAJaHOp2+ebaaO2qVmOCcT1ERGixRofTgWM6idLozr6dDGWHeP3y63xk/UeYbk4nGfq27m28PvY6j699PJmr6Eh1MJQb4nTxNLPNWS6ULySm6esK6xCooaaTMycZyA4k9/TCuvi27m28euFVAB4bfIwT0ycA2Duwl2Kz2K6X34NoB/dVoHWTD+WGeH30dap+FT/2GcoNcbZ4NmEJLMRSP8dWPX4hB/5C6QL//of/nppfQwqlAdKSZS15JY5MHKFgFQhkQE+qB0MYNIOm0pLRDMVtN3NU/ApBHFByS5iamkQcKY0kipC3Am1Z4OvjKnndW4BIqjp7ylDN+I8+9FH8yGe4MEzBKVDxKsmxNa/GS+deYrQ2ynh1nLX5texbu4/+bD/j1XGOTR+jk078yE/EvTZ2bOSd2XeUl69bWhSol9bFn9zwZGLAsfD/B1OD7Xr5PYh2cF8FWjf5Hx3+I9zIRdd1eu1e0mZ6EUtgIZ47+RxhFCZ+qC2rsYUc+GpQ5ZObP8l3Tn1HsVkiFRBagSGWMWVfcdddy8WKrETvY645h6EZyZbcizwKdoF6UKfqVZXOt7y1WfZCLZI2FsPWbDSh0YzeXQmstUC0mqiWrkS8Ss0S6wrrGMgOJLXtzZ2b+cPDf5gMx52aO0UzaJI1s0gk58vnmapP0Zft40LpApZu8cjgI0nPCGCqMcWH1n2IN8ffBNSsxsJA3S6t3L9oB/dVYs/AHgayAxzccXARxWwll/Yj40euq1F9sXyRnJ0jlmp6dDm0pkbDOCRjZdRAU6xGzIUQNHwl8ISAycYkSJLs/XoMmYXQ0BLj5JUgkZiaec1jHkRoaCBUPfy6xwoNIUUyW7BUfrlgFagFNTShJQ5eGzo2MF4d51L1EsVmMWG1/PXJv2Zb1zaaUZOTMycByNtKuCsiQkaSmeYMXuQRxiH9mX4OjR5ia9dWTs2dUtl6s4SlW4u8fNt4b+CmJH8fVFwsX0waSC2sNFW30A+1pTCpoS3SqLZ0i1cvvJroxCwHXeiYmokmNGabs2TNLLquBq7Sehov9ghR1MhYxsTEiVzrajNsgcA2bBzDWXEn0kI7sF+Bjo5A6bPY+vKqoUvR+oxALQoCQU+qB0uoJnnJLxFKtTuruBVSusqyS16JtJFWTfP55nkQBTSiBgc2HGAwO0jKSJG1ssTErMuvI5Rhogq5qWsTGSuDoyshvMfXPp5MQHemOtuB/T2IduZ+A7gRA94Ou4O5huK2O4aDG7rUgzpu5CbDInONOQBM3SSWMV50RbTL0R3SZpoojvBjH13TaQZNTN0kY2So+lVKQSnJ+BZy3yMZEUerb35KJF7oEWux4lPfgonV93oJR0NLXLb80CeIgxt6v1vvja3Zigkj1C4wRn0GhjCIiBirjSnlUCN91X3Wm+5luj4NqCRjqqEMpjWhMdOYSVhSLb/UoltUw3duCVu329n6exzt4L4A17PXu5GpuqUa1S0N7a5UV7KtfnPiTR7pf4Rm2KTkltCFjh/5RDJSDTTTwQsVh1lKJS1gCIP+TD+2aTNTn1k2eN6MGYdEiUvdSGC/1lRry+DhvYqYOPn7bnQ3s9BFSdd0gjig5tWS3ZtpmKSMFKZmous6uqaTt/NXSV2sza9NmqDburdxoXSBqeaUssoLPTX0NL85dwNVMmqGTXRNv6q23sZ7D+2yzDxa7JaFNc2vHPoKxyaOJce0GqudqU5GK6PX3M4e3H4QXdN5uP9hPrXtU3ihp7Jtt8SrF17Fj3y6U91crFzkk5s/SV+mD1M3VdZNTMWvIGPJI/2P4JgOfek+dnTvwNAMphvTic7HaqALHVOY1zymxXy4ESwX2FvX9F4O7AuhC31V7+9CCCGS98mPfaSUSd9EE1pijdfqqfiRz5f3fxld01V2L2OKzSK6pvPl/V9WJZo44BObP8GGjg1YuoUXe4rn7uQxNIOaXyNtpNE0jT/91T/lmQPPtAP7exztzH0eq1V4XC17oLUQfP3w1/nmiW8yUhwhZ+XIWtlE12NL1xaOTB7hYukiY+UxGpFqtpqYOKaDpqm1t9PpZKI+AcBgdlBtu5szyj5PmFfZpi1Fa8FYDhraFaPrecemm8XSTP5B0KvR0UlZKTqcDsbKY4SEV+QCVtgFCQSO6VAP6sqA2lflNjdy0YVOzsolwX8oN0TBKfB3Z/4uYUW1ZiU+MvwRjk8fX7TT9COftfm1fPed75K389SDOtP1aap+lfWd6+m0O9tB/QFBO3Ofx400S28E9aBOwS7Qk+5B13RGq6NEMsIxHC5VLvHIwCMcnjiMH/sYwsDWbKQm8SOf2cYsr158lZSZYlv3NtYX1mMaJk8MP8G+oX1kzAw5M7diBq+h+NGwOMvWlvnYhRBkzMyVn1e5K1gIiVzk5brc66yElufrzUBDw7hLeYovfQSCklui9Za1Smqw/PsYyhApJbZmY2BQDaqK1qpnVAN+vsFeckuUvBJDuSHW5tcmCp9f/OAXObj9IN859Z2rdpqWbi0S7MpaWQayA7yv/33s7d/L3sG9d/LtaeMuoh3c5zFcGE50Mlp4txKkrd2AH/kMZAaUkJmE6fo0Eslsc5budDfdqW4M3cDSrGSISUoV4EMZ0gyaCePG0R2OTBxh7+Bentr4FEITSi1QXAlurcyxZaO29PcLs/hW7bjD6SBn5ZLz3GzG3bJ3szQLy7CueWyLbaKjo+s6XU7XqhcVW7NJG+mkMdliDLUauSthtQtOK/CuhgVT9sqEUYgm1LmFEAxkBjCFmUyrtsxXWtcYxWqBH8oP0el0sr1nO//s4X/G5s7NRDJSzklOgSfXP8mW7i0JQyaMQr7w/Bf453/zz3ln5h28yEse63Q6EQiKbpGh3JBi2TRLNMMma7Jr2tZ1DxjaZZl53A4J0pYmTUu2YG1uLTONGap+lQEG+NjGj+FHPr3pXi6VL6ma93zdtWV+bOkWU/WpRCtGSsmcO8fB7Qc5uP0gbujy5sSbylEnqBPJSNWBNVUL9iJPlV7mg70Qygi5BQ1V481aWQyhxKfC6GrVydUiMW2WioFzLUREmJpJwS5Q82ts7trMVG1KKRhep9TUenzpIiRQi91KdoGrYe/kzBwfGPoAr158lSAKMIRxlRKnqZmLrsGPlLjXBwc/SC2oMV4bxzIstEjD1tWAU8toJaWnQCMpwwznh5ltzmLpFu9f8370CZ3Z5mzyuQBM1iZ5Y+wNzhbPYmgGaTNNGIecnj3Nxs6N/MLQL9Cb6WW0MppMldb9eiJPvbVn61UEgTbe2xC3eorxZvDYY4/Jw4cP3+3LuC5b5kbRMiTwI5/XLr2mgvM8Da5FQ3vu5HOcnj3NDy/8kLHqGJpQhtgS5Y86lBtKAlLFq5AyUzyx9gm++RvfTK7564e/zvfOfY+UkaLklqj7dWpBjZyZU+UezaAZNomiKMlwWzCFcoWKRUzNq6mhKFYO7jr6dRk1BaugGsKryP51dAxdSSkUbDVOL6VM+OCr3UHoLJZauMpkfAGDaOEU6KJyldBI6Sl0odOZ7qTULNEIGhiaoQzK51kxOjpd6S68yKPm1QAlpvXxjR9nV98uYhnznXe+w5Prn8SPfH4+83NOzpxUphlBHVMzldGFUH/7xzZ+jJytymvfO/c9ulPd7B3Yy5GJI1S8Cu/rex/vzL7DTGOGMA6VKYtXIWNmcAxV/ulJ97C7bzdbure0beoeIAgh/lFK+dhyj7Uz9wW41aPWrd1Ap9PJvrX7ODJxhLnmHB/b+DE+/9jnk9f6yqGv8JH1H+H5088rqzyhDKv39u/lTPEMNU+ZevRl+qh6VRphg2+d+NaiZtp/eOo/8OLIi7x0/iWCOGDQHqQ308tMY4bZxuyygT1jZAjigKnmlHJqCtxrBvbVNEgFgoydoeJXrnncwvPZuo2pmVT9KqEMV7WALISOjtCU4Frr+hYmLUupockxC4I9qF2HH/sUbFWv/qUtv8Th8cOq8RmFuIFLNaiSs3NKjldTTldZK0tXuguAbxz5BrONWbzIo9go8lDXQ+zo2UHZLZOzclyqXKIRNpT4m5HC1E10Tefzj32e504+xy9v+eWkmS+E4JXzr/Dj0R8zlB3Cj3yEEBjCSJqrtm7jxR4TtQkulS+Rs3McmzjWztDbaGfutxur2Q0sdHkaKY+wNruWWlBjujHNZG2SLqeLrJ2l4BTY3rOdqlfl+NRxDmw4kJSQzhbPIhBs7Ny4qKw0UZ3gR5d+lAxDtSAQdKW6KLtlQjnP8BDaIoGwm2W7ZMwM9aC+qmMFgu5UN6Caz17kXSntrOK1DQwMXeUoQRSsOttv+cy2egSt12tRGy3d4ouPf5Gp+lTiNZp38lwoXiBn5xirjpEyUhTsAuO1cYIoQNNU+WuhxPK6/DoyVgZTNwmjMLG3+/nMz5XuS6aPr/3i19gzsIfPfvuzrM2vTWr3AOPVcf7y7b9kuDBMyS2Rs3JMN6axdZuaX0PXdKpela5UFxkzwye3fDIRqANu6U60jXsP18rc28H9HsO3TnyLZ199liAO6M30crF0kZyV44nhJ+jP9gPwg5EfcLF8kfUd6xNmxEx9hoylvtwtFJtF/uLEXxDHMW7kUvNVCeFa/PTVBMZrBV4DQ+naRM3rBuhW41XTlMtQykgl5RwD45q7iBZaVM60nqYaVq97/a3mpkQuqqO3ms0tQ/Iup4tf3/XrV+kIeZHHodFDCCkSRkrRLTJaGSWWMY6h5JYNYTDnzmHqJju6d9AMm4nj0ebuzcmCvC6/Di/yGC4MM1GbwNbt5DUna5O8Of4mF8oXWF9Yz3BhmFNzp1R5JgwxDIMojuhJ9ZCxMotckfzIpx7U6XQ6Fy327YnU9xbaZZnr4FbX2m/29Y+MH+HI5BEEgvUd69nes13R7Jolfj7z8yS4XyxfpBE2aAbNRJRsrDq2yJAYSBq5QRwgEEomOFaZ7dLG4tJ69EK0gp4pTDRNmXu3+gJXHatpKzY7l8LUzGSgRyKpB3Us3UqavI2gcc0GaCuwG5qBG7uY2pVBIolM6tOtY+P5/1qaLgv/VolUpSAJtrCRSF4+/zK7enclwbgVHCeqExS9IhW3QsEp8MjgI3zzxDcxhYnQBLZuI4Sgw+6g7JcT+Yjf/9jvJ6W01hCapVv0ZnopNouMVcaQSDaxCTd0E/30D6/7MCemT3B86ji7encRxzHny+fZkN2AF3mJOfajg48mn/t33/ku+9fvv+7cRhvvXTzwwX2p7vpCD8nb9SVY6ig/Vhkjb+c5VzxHxa1g6iYz9RkOuUrBb645x1R9SkkAu2UaYYMOu4NIRlwoX8ANXfzIV1zrBTgzewZd0/FCD13T1Vh67CUBc7lAvvRnQyhDZj/yMQzF0ojc6EqQb43Ro7LhhRor18rcNdQikLfzShFTqmGrjJFhMDPIdGMaN3CvGdwlMqGSjpRGEuaREIp33rru1sLWUm00NEM1T0UKBGpHM08bFQiCKFD3Q24tL5x9gb899bekrTT7h5Uv6UBuIPG+rXk1Dl8+jBu6eMIjbaSZC+aSqVNTM/Ejn75MH1u7t/L0rqcB1WxfmKV3pjrZyEb8yKcz1cm3T36bvJ3nkcFHGMgO0JPp4a3xtzhbPMuv7fw1dvfu5vj0cf7m5N8ghOBD6z6ULP5lV7FybsfcRhv3Dx744L7aydRbhaWLyQtnXlDMh/ltdd5RmXgtqNFv9TPdmGZ3724u1y4nk4k7e3YyWhnlfOn8FdaFZlAP6pyaOZVkmiemT7BvaB/Hp48zU5+faJ2nCVqaRRAHSRa7tIFpaZbiZgsViE3NpBk2VV0+jpCaTMoP9bCeLB4IlHiVvDKhuVyAb9WVU0YKTWj4ho+pmXSlujB1UzWP/SorxXYDA8dyyJgZZhoz6u+KPOaaSoytZSadM3N4sac8ZoVS10wbSk1TIgkitcC4kavq5vOU0bHqGPWgrgxR7BxDuSF+NvUz/vXf/2ul8+NV0NCYbEwSxRE5M0fVryayAKDomprQCKKAodzQoqRhoT9pCwWnwGhllGcOPJM83nqfBrIDfGLzJ5LHAZ7m6aRpb+lWsvgX3SL71u6j7JZXJXLXxnsTD/wQ081Mph6bOMYzLz/DZ7/9WZ55+ZlF+jPXe87S4RM/8slZOUYroziGQ0+6Bykldb+OrdtcLF/kxPQJOuyOpGT05IYncQzlXh/JCFM3GS4Ms7FzY7IIdKY6eajjIR4beoxf2vJL7OzdSd7O05HqIG/llXfr/ADQwsCuo6OhsaVrCzv7duLoDrGME968H/k4psOmjk3s6tuFbdpJOSSxl5NxIku8EmIZY2gGYRSSt/N8cO0H+donv8ajax5l//r9iVTywuGfFjQ0MlaGdbl1XK5eTsobmtRUHV2q7ByUV+iO7h0MZAboTHUqCmPsYQiDjlQHMJ+5xwss8oQyHJ9rzpEyUkQyIm2lydt5zhTP4EUeBzYcoB4qs/K0mWZdxzo2FDYoagQ9zDcAAB9TSURBVKJQ50ob6aTmvaV7C51OJ8+dfA64/tDcaofqVtI7+vxjn6foFhdp0bSHmB4sPPCZ+43I+MLNlXEWPqdVq24ZEhecQmLg0RoX78/2U/WrjFZGqYd1Hl/7OJu6NiWv9emtn+bPwj9jKD9EylB+rm7ksm9oH0Ec8MUPfpHnTj7H+fJ5xmvjPDr4KL+y7VcAeH30dX56+adMN6aXHQDSNT1x/9GFjm0oql0Yh3SnusnbSowqbaY5sOEAf378zzGEQdEtKn9XYtJGGlM3k9LEwjp863WyZhZN09B1nSc3PJlQQ7d2b+Xrh7/O6bnTRFG0LCUyJiaUIRcqF/AiTw1vxVESrFtSDmty/3975x4b13ne6eeby5kL58Lh/SaRMmVaNhVJVuXITmxJjtxFHbhWIAhGvYvATnaRdRxnkay9rjZGNwLaBklaoA6Q1oHR9TYNFtnGhmorcY3NWo7koLJsy5KsUhZ1lyhSpHifGQ7nzPXbP87M0ZDi8E7NcPg9AEHOmUPOe2Z43vOd9/J7G3BYHWyo24B3xEuDp4HrY9fNObjRRJRQLEQ6kUazaTiEw5hDm0qQSCdMm70OL2AMRR+PjxNLxaj11BJwBmj2NwNGD4LD7mBz/WbjjgPMYerZUXi5i4aZmubm0lSXr4Q3d0Teav9qpQK5wljxzn2qk+jiyEVWpVaZuuu5CdbZjM+Dm81FR7uP0jvWS7W7mgdXP0i5q9zQeM8MJF5XtY7DVw5T7a4mmogSS8aMGGrTFzg9eJr7q+7nzso7gZsho46BDh654xFO9J4gFLuZ1HNYHVhSFvNCsrVxK7+98Fte/+x1Kl2VaFaNK6NXaPA24NE8nLpxyqwYsQkbTpuTeCqOVVipclcRT8WN8X2aH4/Dw841OzkzeIbx+DhBPUjfWB+j+ijpdJo6Tx0+h4/uUDd+RyaRa00YjhabGQYC8Gk+vnznl7FZbbdcFDfUbaDWU0uNu4ZL8Ut5P7fxxLg5yCSWjJGUSSwJi+mI22va2da8je5QN6/tes28wPZH+qlyVRFNRNGTOuXOcuLJOPFUHLfNTTgRNhUtrRhyvHrCqDSyCuuEwRzZhHX2Z4DR6Kh5kZn8XO6iIXc+6cnek2YnaXZlP3l+6XycsxqRt7JZ8c598kk0uYrh3OA5vvrPX2VN+Ro21W/i8OXDDOlD047PO9V3ipfee4kLwxfwal5S6RTXw9c5ePkgm2o3TRhI7LA6aK1oxW1z82n/p0ZsHIin4iBvrhqzZFd/39n6HdOJ+51+Lg5f5IOBD9AThsO6t/5eo8LFZseatDIQGSApk+hJnZAewuvw4nP4COpBUqRIyzR60khgRuIRhsaH2N6ynVjK0AV32Bwc7T6K1WJlaHyImrIazgyewa/5GRgfwOfwUeGqIJ6KE4wFuaf6Hi4HLxuStek4aZmmUqvEbXfj0TzTtsN3BbuIJCIzJmTLneUkUsYFRKakMU5OT5o14G989gY1ZTVmU88LD7zA1w98nTODZ7BarDT5mqhyV4GEvkif8ZpSmPozwmKEhexWO9dD1/E7/awNrMXr8Joa6tmKlk11mwjHwnQFu2ivacejeSY8lzt4Ovd/D+DSyCWay5vxO/233Akq56yYLyveucPEFU5uFUPfWB+nB0+bYkwj0RHODJ3BpxmODIwKjxtjN+iP9LPv0D52r9vN/s799Ef68Tl8uOwuyrQyQnqI3nAvoViIJl+T0dZutRFwBXh69dMcOHeAP6j7AzoGOsy4tUTy/tX32d6ynTpPHX1jfZzoPUE8FWd/534eb3ucjoEOo/lp9DLt1e18cv0TukPdnB86j9PmpNJdSYWzgivBK0bYRKbpj/YTShgj3GwWGzItjWqRTH25ZtfoGevhWugaX/3cV/nbY39LSA8xGhtFTxoVJ7XuWq6Hr9PgbWBj3UYGxgcI6kHqvHXcXXU3bz755oRw1FxqrVf7VxNNGnc3WRnkydgsNsNeqw3NpjEWH0NP6qRSKeKpOB39HZTZy2j2NZvOEozEZCQewSqsXA9dJxQPYREWatw1pGSKwfFBbFYbzf5mrMJK35jh9BPpBA2+Br79+W/TVtlmLga2t2wnq4XfVtXG7rt3m+WOuc/Vu+qnXHnf7oS+YuWgnPskcqsYOgc7cVqdOG1OQrEQAVcAt81tViEk00muBq8ipaTKXWWuukJ6iFgyZt6Ou61u+pKGHrtMS5KpJOPJcX6848fsad/DvkP7CDgDfHrjU1w2lxkPTskUyXiSE70n2FS3yVwJbmvexkh0hAPnDphOq7m82SiHjI2asfOB8QGjhDLTtWmuhCVmCAhptLlrFs2oORfCaIu32RmIDPDr87+mvqyeT3o/QQhhzFmVgrPDZ3nkjkdo8Dbc0uiTfbyhbgOPtz3OTz/+KT3hHhq9jTx333MzOq3d63bzysevGNryU6gQaBYNhOHgGz2NDOlDxJNxUiJlhpnsFjvJdJKLoxcJuG4mMlsDrbhsLt7vep902tCzcVqdjMRGqHZVY/fa8WpeKt2VhGNhUjLF2sBas3N178G9/OEdf8g3t3zTPI7c0tas/TC77tB8VTOqZFGxUJRzn0RugjWoB40yuaRuOupV/lV0h7px2V10DnbisDqocFVQ6a40nVpXsAuHzYGe1HHZXYynximzlRFPxxEWQbmrnPaadjoGOtjDHvMEz74eYF5QtjVv46Oej/iw50N8Dh+b6zeb9cwAf3fs7zjafRSAUX0UzaIxGB0kkU5MKyUgkaRkylCCFFZDY95qVOAIiyFZG0vFGNaHSaQM+VmXPaMNLyXhWJjLo5fNbX6nnwtDFzg9cJo15WvYd2gf66vXc+DcATbWbmRb8zaCepAD5w7QVtk2rYPfULeBF7/wIvsO7bvF7qzipc1io8pVhdVqpbaslmgiimbTCMfCOKwOyl3lJNIJRqOjHOk+wse9H1NmL2Nr41YGxgdo8bfgsrvMssaqsioANtdv5si1I0QTUfoifWgWQ0MdAQFrgApnBcd7j0+4G8hNsJ8bPMee1/eYMrvZkEy+pPtcE/oKxWxRzn0SuQlWn9NHMGo0hGS7/7JzKzfWbmQ0Oopm04ilYqyrWgcYTq7cYWijXxi+YJY1IqDeW8/ONTup9dSSlmlzdZY9wbMJOpfdZV5QnDYnu9btuqXuGYzqmoOXD1LpqmQsNkZvuJdkOjlrgS+BoRGvWTTiaUOy1q25jcEiwooNG+XOck72ncSn+czfTaaTaFaNyyOXafI20RXsQkjBcGyY9TXr8Wge3jn/Dj85+hMavY081PyQUV6YinF28CxPvfkUW5u2miGL7MoWmJD7qC6rJjGWMOR0M12r2TuL7z34Pc6PnOfdS+9S6aqk3FnO0PgQFmFBsxo68ulU2hAjSyf5XO3nzK7PtDQSwNn30O/0c1flXRy8fBDNqtFW0caRniP0j/Xj03yM6COAkQepdFaSJj2hrDEbVsmG8YJ60CzhPNpzlAeaHjD3n+zcd6/bzUvvvUR/tzHc2mFzUFNWw1/e+5dz/ddVKCYwo3MXQrwGPAb0SynXZ7ZVAP8EtABXgCeklCNCCAH8BPgyMA48LaU8vjSmLw25CdaAI8CoPsr66vVmi3h2bmXHQIfZOv9A0wOmswjqQTbVbzJCC5lqGavFSp27jgdXPzihizC7OsteUBo8DXQMdBBLxhiKGsqCx3uP01bRxprAmluaUk72naTSVclq/2revfSuKbiVJm04OaGRSqcmiGmZU5KExegqlUaX51h8jMHxQaQ0ukw1i0Z7TTtPb3yab/3Lt4gmorg1Q0NcT+ok0gm8mpcNdRu4MHSBg5cPUmYv4+i1o1wfu27cGaRT9IR7OHLtCG2VbZwbPofD6iASj3D4ymHgZojppfdeYlQfNTtth6JDxJIx7qm6x1CuHO8n4AiYJYjPf/F5TvWdQiA42n2UYCyIEIIGbwOhWIhEKmEmZe1WO/dU3wPAoSuHGIuPEU0a2jfZtn3Nqpn6+idunKDJ24TP7qMv0sdYbIyA05hTejV0lRZ/y4TQyeQwXnY4ePaupnOwk23N2/KGWswLsZj0WKFYALNZuf8D8FPgH3O27QUOSil/KITYm3n8p8CjwJ2Zr63AK5nvi85S6sHkJlgnv042KZbbHeiwOiZ0B2b3eeWxV8y/MVUXYbZyIveCMp4Y59zwOYajw3g1L2sDa0mmk7x/9X0cNgcezUO1u5omXxND0SF2rtnJ2aGzNPmauDhy0RyQYbcYw7azA5fTKWNaUTb2bhNGC75VWPE6vEik0UKfihFPxilzlfH0xqfZ076Hq6NX+Yvf/wXhWNgcHiEwWt77I/2cHjxNIp0gqAcZjRkSCC6bi4RMMBobJTls5CZW+VYhrIJ4Ok6ty7jInR06y46WHVy5bNTktwYMXZVsqKg71M09NfcYsgcyhZ7UuRK8wjO/eYaeUA93BO7gj+/6Yy4OX+Tw1cMkU0mq3dWM6CPoKZ0yexnbm7ebF9Vtzds4dPUQw9FhKl2V3N90P5pVMxO9ubK7vzn3G6zjRrllJBnBZ/EZeQAx8eI8OYyX7ewFI7wW1IN5Qy37O/fTGmhlS8NN7aeR6IhKqCoWzIzOXUr5vhCiZdLmXcCOzM8/Bw5hOPddwD9KQ2ryqBCiXAhRL6XsXSyD4fbqwUxXjjbbWuTZ7Jf7Ojv+YQeaRZvQQRlPxZFSsiawhoHIAKP6KJvrNpvOo8JVQTgeJhwLE0/FzdZ3h81h6KpYdKwpo267TCszyhutDmMUnjRCC/WeekKxELvW7WIkOmLmBJ7/4vM0lzebidF4Os7DLQ/TXtPOoSuHcFqd+DQfPeEehDCkg3PlhfWUjkxJzg6eNUsws0Mmsl2Y/ZF+M0wUS8Vw2ozO2FA8ZNTMpxJcHLlIg7eBbc3bzBr/bKjK5/ARcAa4FrxGb6TX0LiREiEnjtxz2pw8uf5Js6qpK9g1oZLl5Q9fNlfi4XgYu9VOJBEhHo/jsrlY7V/NeGJ8wsV5chivTDNm0UYTUSTSvHhM1YCkEqqKpWK+MffaHIfdB2QzfI3AtZz9ujPbbnHuQohvAN8AWL16bsmjYiofm20t8lxqlnvCPdSX1ZuPB8cHcdkMp/dwy8PATfnZEX0EzaoRTUbx2D0E9SAt5S1IKRmJjWDBQm1ZLV7Ny3BsmEZPI5FkhM/6P0MieWj1Q1wYvkCZrWxC4niyg9nTvscUvXrmN8+YIla9Y700ehvxaB7SpM1Qj3nXIK2mXrwQxvi98cQ4w9Fh3Ha3+XppmTZj5U6bk0Qqgd1ip8xuaO5cGrmER/OYZaEf9XyEV/NyZvAMAEeuHTE6YmWSdDqNTdhw2V2MJcd4+/zbSClp8DVMuLOa6vPI5j9iqZghxCahwlVBImUoa47qo6wuXz1hITE5jHdfw314NE/e4SxTvZ5KqCoWmwVry2RW6XMOEkopX5VSbpFSbqmurp75F3KYjx7M7WQ+2jO5NHobzZZ1MJJ+KZma0NDkd/qJp+K88MAL3Ft/L8PRYcq0Mnau2WlIwKZ0Hm97nLf//dsc+8/H+N3XfscvvvILPt/0eQKOAM3lzbhsLrqCXcZ8Tz2IntS5u+puIL+DOdV3ip5QD6FYCLvFjlVYuTRyiXg6jsduOPiUTBkaLRnxMIEg4AwY4Y1EBI/dQ++YUfN/V+VdnB86TxojXPVZ/2eEY2EGo4MM68PUltWysXYjfqefx9oeM3MbfqffDI+cGTyD02aUMyZSCTRrZji3AL/Dj0Dw+2u/N3VXprvI7l63mxF9hBO9J6hyVZGSKWLJGKv8q6j31ON1es3hGlk21G1g3459vPnkm/ziK7/gzso7SaQTPHrno+x/Yj8/e+xneV8z+3pKA0ax2Mx35X4jG24RQtQD/ZntPcCqnP2aMtsWlWJe7SxGyOi5+57jxXdfBAx9EimNePi25m3mPtnj3VC3gZ899rMJuYFHax+dMgeR2xH5xfIvoid1TvadpD/Sj8vu4r6G+8zEcb4wwv7O/dwRuIMmXxMf93yMntSJJqMMjA3gtruJJqLmgO8EN+UGvA4vFmFBT+pEkhEqXBXsaNlBb7iXy6OX2dqwlY7+Dm6M3TCkBDLVMUPRIeKpOI/c8YjZ9g+Ysg0+h4/eUC9jyTEGI4PmzFgrVpLpJH6H38wrzGa2aDaE9tSbT2G32Gnxt4AwVCb9Lj8BR2DGMs65SgQoDRjFUjBf534AeAr4Yeb7WznbnxNC/B+MRGpwsePtMDdRpdvNYoSMsuGPbIx7lX8VLpuLBm/DlAlZmL1TmWxfvbfeDEPUeepmdDDZGHF/pJ+ETLC2Yi2JVILOoU7SiTRNvib0lG4M6Y6PYbfYcdvdJNIJrBYrbRVtRFNRnmh/gn079rHv0D6ay5sJuAJcCV5hMDqIkAKn1UmTr8ms1X92y7MTPvNc2Ybzw+fRLBoBZ4Dh6LCpM69ZNbOpqdHbOKv3PvteZvMO+Rq0FhMlM6BYCmZTCvlLjORplRCiG/g+hlP/lRDiPwJXgScyu/8LRhnkBYxSyK8tgc1FvdpZrARZbowb8lftLJZ9uTrhk8l97Usjl9ATOtfHruO0Os1yP5/Dx2rfatyaoRYJ8Ouzvzb2T+m4hItGT6MpUZwNO+TaMxwdJuAMGENFUjGqyqoYj49ztPsorzz2yi2f+Q/u/QH7O/djt9rp6O8gLdNEk1HC8TCxZIwyexnj8XHcdjfP3ffcnN6nYl5AKBSzYTbVMk/meWrnFPtK4FsLNWo2FOtqZ6lCRgs53snOOZaMmUqTM9k3OcwUSxozRAGavE2mumKTr8mMgWdZV7WOZDpJe3U7PWM9DEQGsFvs/NlDf2Yey1TvV1ImzWqarOZNvvfg5Q9fprWiFZ/Dx5nBM0YidtzOWGKMlEzRGmhl74N7J1woZ0MxLyAUitlQsh2qhZqLWmwrvsnOWU/opnNurWid0b7JYZzsReFfr/0rg9FBaspq2Fy/GYk0Y+DZ0FFuw5fT7uThlodv+RzWV6/nz3//52Y1SjgWRrNp1PnqiCaihGNhtrdsz3t82YtDrafWrGXPXixmE2OfjmJdQCgUs6EknXsh5qJmKbYV32Tn3FbVBhjllg6bY0b7pgrjtFa0EolH8Dl9ExQfWytaWeVbZY4DzG34mopTfac4cO4A7VXGyj6WNAZv+DU/KVLYsNFa0cqzW57Ne3zFdjFVKIqFknTuha6DL6YV31TOeW3lWpx2pzmx6eUPX857d5MvzJSVWJgcA5/Lced+TtmLzvmh8/SEjc7T2dxxFdvFVKEoFkrSuauuv5vkc86aVZvV3c10K+N8F7HZhsTy3RU4bA5e2/XarI+xmC6mCkWxUJIDsmc7XLiYWWgjVPZv3Bi7wdvn3+ad8+/QG+41a9izjUUBVwCLsBBwBSYoHWbJN4B5pnmxI9GRCReNqewvhc9JoShWStK5L/euv7k4yJn+hmbV2LnGKGw6ePkgsVSMFx54gd5wLydvnOStzrc4dOUQfWN9ee9ush2Yr+16jX079k27Ss4NtUx30YDl/zkpFMVMSYZllmscNhvOeKvzLTSrxr3195oOEuaWM8jXrJR9fDl4GSGFqSH/QfcHtFe1m7Hv+TKXkNhy/ZwUiuVASTp3WH5x2NwKHyklEskH3R+YWvFzzRlM52T3d+5nffV6Ovo70JM6TpuTWDLG6YHT7H1w74KOY651/svtc1Iolgsl69xnS6Hq4SeTu9Iud5UTTRgDojsHO6nz1M3YaDT5GKZzsl3BrgmNP0E9iN/pJ+CcXjdlNqjSRIWiOCjJmPtsWYzY9mKRq3R5d9Xd6EkdKSWj+ui0seh8x7C+en3eeHY2kVnrqWVHyw52rdvFprpNbKrftODjmGsCVqFQLA0reuVe6Hr4XHJX2rWeWr6w6gsc7z1u2pUvFp3vGDoGOqaNZy/l6lqFWhSKwrOinftS1MPPN8wzOZyhWTXuqrprxlXvdMeQz8mqRKZCUfqsaOe+2CJfC5E9mK/Dne8xFNvq+lTfKXOguERyf9P9eacXKRSKmVnRzn0hyb+pVugLDfPMx+HO5hiKJWmcj1N9p3jpvZe4MHwBr+YFAYevHKY71M0PvjQ3SQOFQmGwohOq803+5Utinuw9edvH/810DMWUNM7H/s799Ef68Tl8uDU3brsbn8PHQGRgyuYnhUIxMyt65Q7zWy3nW6F3BbsI6sHbPv5vumMopqRxPrqCXcSSsQkXRqfNSTAWXJF6QArFYrCiV+7zJd+A7nJHedG10xf7MHEw8gYOmwM9qZvb9KSOw+pQOjMKxTxZ8Sv3+TAXGdy5VqEsdny8mIeJZ9m9bjefXP+EC8MXkFKCgHAsTGtFq9KZUSjmiTAm4xWWLVu2yGPHjhXajFmTWxWTm8RcaLPOUvzdpbJ1sVHVMgrF3BFCfCKl3DLlc8q5z4+lqEDZd2jfLavsxRgZV+zVMgqFYn5M59xVWGaeLEWd+EKbqvI58WKraVcoFEuPSqgWEQsZXrEcSh4VCsXtQzn3ImIhwyvmMiRDoVCUPsq5FxELUVRcDiWPCoXi9qFi7kXGfOPjy6HkUaFQ3D6Ucy8R5qOTo6poFIrSRYVlSoS5hnRUAlahKG3Uyr2EmEtIZzlozigUivmjVu4rFJWAVShKG+XcVygLqalXKBTFj3LuK5SF1NQrFIriRzn3FcpCauoVCkXxoxKqKxilOaNQlC5q5a5QKBQlyIKcuxDiu0KI00KIDiHEL4UQTiHEGiHEh0KIC0KIfxJCaItlrEKhUChmx7yduxCiEfgvwBYp5XrACvwJ8CPgb6SUa4ERIH+LpEKhUCiWhIWGZWyASwhhA9xAL/Al4I3M8z8HvrLA11AoFArFHJm3c5dS9gB/DXRhOPUg8AkwKqVMZnbrBhoXaqRCoVAo5sZCwjIBYBewBmgAyoA/msPvf0MIcUwIcWxgYGC+ZigUCoViChZSCvkIcFlKOQAghNgPfBEoF0LYMqv3JqBnql+WUr4KvArGDNUF2DElSvFQoVCsZBYSc+8C7hdCuIUQAtgJfAb8DtiT2ecp4K2FmTh3lOKhQqFY6Swk5v4hRuL0OPBvmb/1KvCnwH8VQlwAKoH/uQh2zgk1ck6hUKx0FtShKqX8PvD9SZsvAZ9fyN9dKF3BLpp8TRO2KcVDhUKxkijJDlWleKhQKFY6JencleKhQqFY6ZSkc1eKhwqFYqVTsqqQSvFQoVCsZEpy5a5QKBQrHeXcFQqFogRRzl2hUChKEOXcFQqFogRRzl2hUChKECHlomt2zd0IIQaAq0v8MlXA4BK/xlKhbC8MyvbCsZztv522N0spq6d6oiic++1ACHFMSrml0HbMB2V7YVC2F47lbH+x2K7CMgqFQlGCKOeuUCgUJchKcu6vFtqABaBsLwzK9sKxnO0vCttXTMxdoVAoVhIraeWuUCgUKwbl3BUKhaIEKUnnLoQoF0K8IYToFEKcEUI8IIT4q8zjU0KIfxZClBfaznxMZX/Oc88LIaQQoqqQNuYjn+1CiG9ntp0WQvy40HZORZ7/m01CiKNCiJNCiGNCiIJOGZsKIcRdGfuyXyEhxHeEEBVCiP8nhDif+R4otK2Tmcb2oj9f89me83xhz1UpZcl9AT8H/lPmZw0oB/4dYMts+xHwo0LbORf7Mz+vAv4vRsNXVaHtnMN7/zDwLuDIbK8ptJ1zsP23wKOZbV8GDhXazhmOwQr0Ac3Aj4G9me17i/l/fgrbl835Otn2zOOCn6slt3IXQviBbWQGc0sp41LKUSnlb6WUycxuR4GmfH+jkOSzP/P03wAvAkWZBZ/G9m8CP5RSxjLb+wtn5dRMY7sEfJnd/MD1wlg4a3YCF6WUV4FdGBcsMt+/UjCrZodp+3I5X3PIfd+hCM7VknPuwBpgAPhfQogTQoi/F0KUTdrn68A7t9+0WTGl/UKIXUCPlPLTAts3Hfne+zbgISHEh0KIw0KI+wpr5pTks/07wF8JIa4Bfw3890IaOQv+BPhl5udaKWVv5uc+oLYwJs2aXNtzKebzNYtpe7Gcq6Xo3G3AZuAVKeW9QATjlhQAIcRLQBL434Uxb0amsn8f8D3gfxTQrtmQ7723ARXA/cB/A34lhBAFs3Jq8tn+TeC7UspVwHfJrOyLESGEBjwOvD75OWnECoryjg/y274MztcJtgsh3BTJuVqKzr0b6JZSfph5/AbGSYsQ4mngMeA/ZP7Zi5F89q8BPhVCXMG4RT0uhKgrjIl5yWd7N7BfGnwEpDHElYqJfLY/BezPbHsdKLqEag6PAsellDcyj28IIeoBMt+LLhyWw2Tbl8v5ChNtb6VIztWSc+5Syj7gmhDirsymncBnQog/woiBPS6lHC+YgTOQx/7jUsoaKWWLlLIFwxFtzuxbNOR774E3MZKqCCHaMJKVRaX4N43t14HtmW1fAs4XwLzZ8iQTwxoHMC5OZL6/ddstmj0TbF8u52sG03Yp5b8Vy7lakh2qQohNwN9jOJFLwNeAjwEHMJTZ7aiU8pnCWDg9U9kvpRzJef4KsEVKWVQOEvK+9xHgNWATEAdekFK+VzAj85DH9nbgJxhhGx14Vkr5ScGMzEMmP9AF3CGlDGa2VQK/AlZjVG08IaUcLpyVU5PH9gssg/N1KtsnPX+FAp2rJencFQqFYqVTcmEZhUKhUCjnrlAoFCWJcu4KhUJRgijnrlAoFCWIcu4KhUJRgijnrlAoFCWIcu4KhUJRgvx/HpHIBma045wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6LGwlUSYkqZ",
        "outputId": "b288a373-3f62-489d-e641-a47f6130e7a2"
      },
      "source": [
        "#RMSE Root Mean Squared Error\n",
        "rms = math.sqrt(mean_squared_error(x_test, predicted))\n",
        "rms"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59.19298169573189"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV3IF0obY1aX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}